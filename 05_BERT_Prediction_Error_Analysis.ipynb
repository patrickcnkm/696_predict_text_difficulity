{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3c1e9a",
   "metadata": {},
   "source": [
    "# BERT Prediction Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64fc66",
   "metadata": {},
   "source": [
    "This code is used to:\n",
    "- Verify the impact from text preprocessing on BERT.\n",
    "- Utilize the unsupervised learning to look for the patterns of error data\n",
    "\n",
    "In order to speed up the issue analysis, only 1% of total training data(random sampling) is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb7d23c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Disable 3 types of warning\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\",category=(FutureWarning))\n",
    "warnings.filterwarnings(\"ignore\",category=(RuntimeWarning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffe1b70b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-7d4f7d9d47d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrange\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnotebook\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclassification_report\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprecision_recall_fscore_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAdamW\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mget_linear_schedule_with_warmup\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mDistilBertForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_distributor_init\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__check_build\u001b[0m  \u001b[0;31m# noqa: F401\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 82\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbase\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mclone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     83\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_show_versions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mshow_versions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m__version__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0m_config\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_IS_32BIT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m from .utils._tags import (\n\u001b[1;32m     19\u001b[0m     \u001b[0m_DEFAULT_TAGS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/utils/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmurmurhash\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmurmurhash3_32\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mclass_weight\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcompute_class_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_joblib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDataConversionWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/utils/class_weight.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mvalidation\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_deprecate_positional_args\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcontextlib\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msuppress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mfixes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_object_dtype_isnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparse_version\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_config\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_get_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexceptions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPositiveSpectrumWarning\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Library/Python/3.7/lib/python/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlsqr\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msparse_lsqr\u001b[0m  \u001b[0;31m# noqa\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mma\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMaskedArray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0m_MaskedArray\u001b[0m  \u001b[0;31m# TODO: remove in 1.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scipy/stats/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m \"\"\"\n\u001b[0;32m--> 388\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    389\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mdistributions\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    390\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmorestats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scipy/stats/stats.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    178\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mscipy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mspecial\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mspecial\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlinalg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 180\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdistributions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    181\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmstats_basic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m from ._stats_mstats_common import (_find_repeats, linregress, theilslopes,\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scipy/stats/distributions.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m                                     rv_frozen)\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_continuous_distns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0m_discrete_distns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scipy/stats/_continuous_distns.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m   8104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8106\u001b[0;31m \u001b[0mwrapcauchy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwrapcauchy_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'wrapcauchy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8108\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, momtype, a, b, xtol, badvalue, name, longname, shapes, extradoc, seed)\u001b[0m\n\u001b[1;32m   1599\u001b[0m                  shapes=None, extradoc=None, seed=None):\n\u001b[1;32m   1600\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1601\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrv_continuous\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1602\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1603\u001b[0m         \u001b[0;31m# save the ctor parameters, cf generic freeze\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scipy/stats/_distn_infrastructure.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, seed)\u001b[0m\n\u001b[1;32m    582\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    583\u001b[0m         \u001b[0;31m# figure out if _stats signature has 'moments' keyword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 584\u001b[0;31m         \u001b[0msig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getfullargspec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    585\u001b[0m         self._stats_has_moments = ((sig.varkw is not None) or\n\u001b[1;32m    586\u001b[0m                                    \u001b[0;34m(\u001b[0m\u001b[0;34m'moments'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/scipy/_lib/_util.py\u001b[0m in \u001b[0;36mgetfullargspec_no_self\u001b[0;34m(func)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[0mvarargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvarargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mvarargs\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m     varkw = [\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mParameter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mVAR_KEYWORD\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "import os\n",
    "from tqdm import trange\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from transformers import AdamW,get_linear_schedule_with_warmup\n",
    "from transformers import BertForSequenceClassification,DistilBertForSequenceClassification\n",
    "from transformers import BertTokenizer,DistilBertTokenizer\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c3fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import helper functions\n",
    "\n",
    "from helper import train_dev_test, convert_examples_to_inputs,get_data_loader,data_evaluation,duple_labels,elbow_plot,train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7de7206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enable GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc24b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable logging.\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f401eebc",
   "metadata": {},
   "source": [
    "##### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80adf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# load train data\n",
    "source_train_data_path=\"./01_data/WikiLarge_Train.csv\"\n",
    "source_train_data=pd.read_csv(source_train_data_path)\n",
    "\n",
    "RANDOM_STATE=1\n",
    "PORTION=0.01\n",
    "size=round(len(source_train_data)*PORTION)\n",
    "train_data=source_train_data.sample(n=size,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d20a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Plot histogram with the length. Truncate max length to 5000 tokens.\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "train_data['length'] = train_data['original_text'].apply(lambda x: len(x.split()))\n",
    "sns.distplot(train_data[train_data['length'] < 5000]['length'])\n",
    "plt.title('Frequence of sentences of a given length', fontsize=14)\n",
    "plt.xlabel('length', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bcb0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT token length should not be more than 512.\n",
    "data_describe=train_data['original_text'].apply(lambda x: len(x.split())).describe()\n",
    "print(data_describe)\n",
    "MAX_SEQ_LENGTH=int(data_describe['max'])\n",
    "if MAX_SEQ_LENGTH>512:\n",
    "    MAX_SEQ_LENGTH=512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce485e25",
   "metadata": {},
   "source": [
    "#### Verify the impact from text preprocessing\n",
    "\n",
    "The following situations will be considered respectively:\n",
    "- Initial status - Pretrain: evaluate the test dataset without training.\n",
    "- Fine tune without preprocessing: train the bert, then evaluate the test dataset.\n",
    "- Remove stopwords,train the bert, then evaluate the test dataset.\n",
    "- Correct mis-spelling,train the bert, then evaluate the test dataset.\n",
    "- Lemmanization,train the bert, then evaluate the test dataset.\n",
    "- Remove duplicate records (same label),train the bert, then evaluate the test dataset.\n",
    "- Remove duplicated records ( different label),train the bert, then evaluate the test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a472e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize the parameters for training / evaluation\n",
    "params={\n",
    "        \"GRADIENT_ACCUMULATION_STEPS\":1,\n",
    "        \"NUM_TRAIN_EPOCHS\":8,\n",
    "        \"LEARNING_RATE\":2e-5,\n",
    "        \"WARMUP_PROPORTION\":0.1,\n",
    "        \"MAX_GRAD_NORM\":5,\n",
    "        \"MAX_SEQ_LENGTH\":MAX_SEQ_LENGTH,\n",
    "        \"BATCH_SIZE\":16,\n",
    "        \"NUM_WARMUP_STEPS\":600\n",
    "}\n",
    "BERT_MODEL = \"distilbert-base-uncased\"\n",
    "OUTPUT_DIR = \"./tmp/\"\n",
    "MODEL_FILE_NAME = \"pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb83a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc=pd.DataFrame(columns=['description','accuracy','texts','labels','prediction'])\n",
    "list_acc=['Pretrain','Fine tune without preprocessing',\n",
    "                       'Removal of stopwords','Correction of spelling',\n",
    "                      'Lemmatization','Removal of duplicate records with same labels',\n",
    "                      'Removal of duplicate records with different labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91937573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_preprocessing import preprocess_text\n",
    "from text_preprocessing import check_spelling,remove_stopword,lemmatize_word\n",
    "\n",
    "for i in range(len(list_acc)):\n",
    "    ### prepare for data based on different situation\n",
    "    process_data=train_data.copy()\n",
    "    if list_acc[i]=='Removal of stopwords':\n",
    "        process_data['original_text'] = process_data['original_text'].apply(lambda x:' '.join(remove_stopword(x)))  \n",
    "    \n",
    "    if list_acc[i]=='Removal of stopwords':\n",
    "        process_data['original_text'] = process_data['original_text'].apply(lambda x:' '.join(check_spelling(x)) if type(x)=='str' else x) \n",
    "\n",
    "    if list_acc[i]=='Correction of spelling':\n",
    "        process_data['original_text'] = process_data['original_text'].apply(lambda x:' '.join(remove_stopword(x)))      \n",
    "       \n",
    "    if list_acc[i]=='Removal of duplicate records with same labels':\n",
    "        process_data.drop_duplicates(subset=['original_text','label'],inplace=True)\n",
    "\n",
    "    if list_acc[i]=='Removal of duplicate records with different labels':\n",
    "        # look for the records with different labels \n",
    "        df_2labels=process_data.copy()\n",
    "        df_duple_labels=duple_labels(df_2labels)\n",
    "        # Indentify double labels in data\n",
    "        df_2labels['duplicated']=df_2labels.duplicated(subset=['original_text'])\n",
    "        df_2labels=double_data_unique.merge(df_duple_labels,how=\"left\",left_on=\"original_text\",right_on=\"original_text\")\n",
    "        df_2labels['label_y']=df_2labels['label_y'].apply(lambda x: '0' if pd.isnull(x) else '1') # 0 means 1 label, 1 means 2 labels\n",
    "        df_2labels=pd.DataFrame(df_2labels[['original_text','label_x','label_y','duplicated']])\n",
    "        df_2labels.columns=['original_text','label','dulabel','duplicated']\n",
    "        process_data=df_2labels[df_2labels['dulabel']=='0'].copy()\n",
    "\n",
    "    _,(train_texts,dev_texts,test_texts),(train_labels,dev_labels,test_labels),\\\n",
    "                                        (target_names,label2idx)=train_dev_test(process_data,random_state=RANDOM_STATE)\n",
    "\n",
    "    ### Train model if it is not in \"pretrain\"\n",
    "    if list_acc[i]!='Pretrain':\n",
    "        train(BERT_MODEL,train_texts,train_labels,dev_texts,dev_labels,target_names,label2idx,params)\n",
    "        train_flag=True\n",
    "    else:\n",
    "        train_flag=False\n",
    "\n",
    "    ### Evaluate model\n",
    "    _,pred,acc=data_evaluation(test_texts,test_labels,BERT_MODEL,params,trained=train_flag,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)\n",
    "    \n",
    "    ### Save the output including dataset, accuracy results.\n",
    "    df_acc.at[i,'description']=list_acc[i]\n",
    "    df_acc.at[i,'accuracy']=acc\n",
    "    df_acc.at[i,'texts']=(train_texts,dev_texts,test_texts)\n",
    "    df_acc.at[i,'labels']=(train_labels,dev_labels,test_labels)\n",
    "    df_acc.at[i,'prediction']=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4cd993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "bars = alt.Chart(df_acc).mark_bar().encode(\n",
    "    x='accuracy:Q',\n",
    "    y=\"description:O\"\n",
    ")\n",
    "\n",
    "text = bars.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=3  # Nudges text to right so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    text='accuracy:Q'\n",
    ")\n",
    "\n",
    "rule = alt.Chart(df_acc[df_acc['description']=='Pretrain']).mark_rule(color='red').encode(\n",
    "    y='accuracy:Q'\n",
    ")\n",
    "(bars + text + rule).properties(height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef1dd60",
   "metadata": {},
   "source": [
    "##### Impact investigation on similar text"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce95ae9",
   "metadata": {},
   "source": [
    "Compare the embeddings between error records in test set with training set + test set ( including error record), find out the similar \n",
    "records,display the numbers of different labels to check whether the portion of label could impact the classification records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6af12279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Introduce sentence-BERT\n",
    "from sentence_transformers import SentenceTransformer\n",
    "onlinemodel='all-mpnet-base-v2'\n",
    "embedder = SentenceTransformer(onlinemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f769ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.DataFrame(columns=['original_text','label','err','init_pred','best_pred','cnt_1','cnt_0','avg_1','avg_0'])\n",
    "df_test['original_text']=df_acc[df_acc['description']=='Fine tune without preprocessing']['texts'][2]\n",
    "df_test['label']=df_acc[df_acc['description']=='Fine tune without preprocessing']['labels'][2]\n",
    "df_test['init_pred']=df_acc[df_acc['description']=='Pretrain']['prediction']\n",
    "df_test['best_pred']=df_acc[df_acc['description']=='Fine tune without preprocessing']['prediction']\n",
    "df_test['err']=df_test['best_pred']-df_test['label']\n",
    "df_test['err']=df_test['err'].apply(lambda x: 1 if x!=0 else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a459ffc",
   "metadata": {},
   "source": [
    "Compare the embeddings between error records in test set with training set + test set ( including error record), find out the similar \n",
    "records,display the numbers of different labels to check whether the portion of label could impact the classification records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dataset for comparison,remove duplicate and different label\n",
    "#df_train=train_data_unique.copy()\n",
    "#df_comp=pd.concat([pd.DataFrame(df_train[['original_text','label']]),pd.DataFrame()],\n",
    "#                  ignore_index=True)\n",
    "\n",
    "#Assign the index to identify each row\n",
    "#df_comp=df_train.copy()\n",
    "df_comp['original_text']=df_acc[df_acc['description']=='Fine tune without preprocessing']['texts'][0]\n",
    "df_comp['label']=df_acc[df_acc['description']=='Fine tune without preprocessing']['labels'][0]\n",
    "df_comp=df_comp.reset_index()\n",
    "\n",
    "\n",
    "# Create the embedding for comparison dataset\n",
    "query_embeddings=embedder.encode(df_comp['original_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab673503",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['id']=df_test.index\n",
    "df_test['id']=df_test['id'].apply(lambda x: 'e'+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# work out the similarity and identify the record of self\n",
    "\n",
    "# Set the simlarity threshold \n",
    "THRESHOLD=0.5\n",
    "\n",
    "#Create dateset to cluster the similar sentence\n",
    "err_cluster=pd.DataFrame(columns=list(df_comp.columns)+['score','cluster'])\n",
    "\n",
    "df_err=df_test[df_test['err']==1]\n",
    "for i in trange(len(df_err)):\n",
    "    #print(df_test[df_test['err']==1]['original_text'].iloc[i])\n",
    "    df_temp=pd.DataFrame(columns=err_cluster.columns)\n",
    "    str_to_predict=df_test[df_test['err']==1]['original_text'].iloc[i]\n",
    "    #print(str_to_predict)\n",
    "    sim=cosine_similarity([embedder.encode(str_to_predict)],query_embeddings)\n",
    "    j=np.argmax(sim)\n",
    "    sim_rows=list(np.where(sim[0]>THRESHOLD)[0])\n",
    "    if sim_rows !=[]:\n",
    "        #print(set(np.where(sim[0]>THRESHOLD)[0]))\n",
    "        \n",
    "        if err_cluster.empty:\n",
    "            df_temp=df_comp.iloc[sim_rows]\n",
    "        else:\n",
    "            #print(set(err_cluster['index']))\n",
    "            #df_temp=df_comp.iloc[list(set(sim_rows)-set(list(err_cluster['index'])))]\n",
    "            df_temp=df_comp.iloc[sim_rows]\n",
    "            # (df_temp)\n",
    "        \n",
    "        if df_temp.empty== False:\n",
    "            #print(sim[0][sim_rows])\n",
    "            df_temp['score']=sim[0][sim_rows]\n",
    "            df_temp['cluster']=df_err['id'].iloc[i]\n",
    "            \n",
    "            \n",
    "            err_cluster=pd.concat([err_cluster,df_temp],axis=0,ignore_index=True)\n",
    "            #print(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f30372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a3593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e06216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the records whose similar recods have 2 diferent labels\n",
    "df_group=err_cluster.groupby(['cluster','label']).count().reset_index().groupby('cluster').count()\n",
    "df_group[df_group['label']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d47a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_cluster[err_cluster['cluster']=='e100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf298801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err[df_err['id']=='e100']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab38f65",
   "metadata": {},
   "source": [
    "Change label and retrain the model ,see whether it could impact the evluation result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0b84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train, dev, test data\n",
    "df_comp.iloc[4088]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30313fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.at[4088,'label']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1cc024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.at[4088,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d791f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_text=df_comp['original_text']\n",
    "orig_train_label=df_comp['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb42f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(BERT_MODEL,orig_train_texts,orig_train_labels,orig_dev_texts,orig_dev_labels,target_names,label2idx,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88824f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,orig_pred,orig_acc=data_evaluation(orig_test_texts,orig_test_labels,BERT_MODEL,params,trained=True,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4523835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_test_texts[100],orig_pred[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c27505",
   "metadata": {},
   "source": [
    "Apparently, after chaning one record's label from 1 to 0, the result of evaluation is changed as well.\n",
    "Let's change the label back, and take further test again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7589057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.at[4088,'label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc9427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.at[4088,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d272ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_cluster[err_cluster['cluster']=='e9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2a26e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err[df_err['id']=='e9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc522e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.at[3467,'label']=0\n",
    "df_comp.at[642,'label']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.at[3467,'label'],df_comp.at[642,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d06a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_text=df_comp['original_text']\n",
    "orig_train_label=df_comp['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29617a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(BERT_MODEL,orig_train_texts,orig_train_labels,orig_dev_texts,orig_dev_labels,target_names,label2idx,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cabef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,orig_pred,orig_acc=data_evaluation(orig_test_texts,orig_test_labels,BERT_MODEL,params,trained=True,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d3661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_test_texts[9],orig_pred[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeeba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_cluster[err_cluster['cluster']=='e103']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad0d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err[df_err['id']=='e103']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cbfcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_cluster[err_cluster['cluster']=='e111']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a227c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err[df_err['id']=='e111']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ab05ab",
   "metadata": {},
   "source": [
    "##### Final report 5.3 - Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881744b1",
   "metadata": {},
   "source": [
    "Step 1. Create dataset for unsupervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2bfed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the embedding for comparison dataset\n",
    "df_train=train_data_unique.copy()\n",
    "df_train['type']='train'\n",
    "df_train['err']='0'\n",
    "df_test['type']='test'\n",
    "df_cluster=pd.concat([pd.DataFrame(df_train[['original_text','label','type','err']]),\n",
    "                   pd.DataFrame(df_test[['original_text','label','type','err']])],\n",
    "                  ignore_index=True)\n",
    "\n",
    "#Assign the index to identify each row\n",
    "df_cluster=df_cluster.reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed1443",
   "metadata": {},
   "source": [
    "Step 2. Using sentence-BERT to create the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859dda3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_embeddings=embedder.encode(df_cluster['original_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d65885c",
   "metadata": {},
   "source": [
    "Step 3. Run PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4109f2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering algorithms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Using PCA to reduce the dimension to project the result to 2-d scatter plot\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(cluster_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886fb438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "df_pca['sentence_id']=df_cluster.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dabdd3",
   "metadata": {},
   "source": [
    "Step 4. Run Elbow method to find out optimal K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b04e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Elbow for full training data\n",
    "elbow_plot(principalComponents,maxK=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85959e16",
   "metadata": {},
   "source": [
    "Step 5. Run Kmeans to cluster the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d523da",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 2\n",
    "clf = KMeans(n_clusters=num_clusters, \n",
    "            max_iter=100, \n",
    "            init='k-means++', \n",
    "            n_init=1)\n",
    "clf.fit_predict(cluster_embeddings)\n",
    "cluster_assignment = clf.labels_\n",
    "\n",
    "cdf=pd.DataFrame(columns=[\"cluster_id\",\"sentence_id\",\"sentence\"])\n",
    "\n",
    "for i in range(len(cluster_assignment)):\n",
    "    new_row=pd.Series(data={\"cluster_id\":cluster_assignment[i],\n",
    "                                \"sentence_id\":i,\n",
    "                                \"sentence\":df_cluster.iloc[i]['original_text'],\n",
    "                                \"label\":df_cluster.iloc[i]['label'],\n",
    "                                \"err\":str(df_cluster.iloc[i]['err'])\n",
    "                           }\n",
    "                            )\n",
    "    cdf=cdf.append(new_row,ignore_index=True)\n",
    "\n",
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd4879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine PCA results with K-means results to see clustering\n",
    "df_k=df_pca.merge(cdf,right_on=['sentence_id'],left_on=['sentence_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a6cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14e72aa",
   "metadata": {},
   "source": [
    "Step 6. Plot clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb7ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "alt.Chart(df_k).mark_point(size=60).encode(\n",
    "    x='principal component 1',\n",
    "    y='principal component 2',\n",
    "    shape='err:N',\n",
    "    color=alt.Color('cluster_id', scale=alt.Scale(scheme='category20c')),\n",
    "    tooltip=['sentence','sentence_id','label']\n",
    ").properties(title='PCA & Kmeans',height=400,width=500).interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdf35cc",
   "metadata": {},
   "source": [
    "Using UMAP & HDBSCAN  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d26170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "umap_embeddings = umap.UMAP(n_neighbors=30, \n",
    "                            n_components=2, \n",
    "                            metric='cosine').fit_transform(cluster_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175351bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "cluster = hdbscan.HDBSCAN(min_cluster_size=2,\n",
    "                          metric='euclidean',                      \n",
    "                          cluster_selection_method='eom').fit(umap_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc88e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689ea577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uh = pd.DataFrame(data = umap_embeddings\n",
    "             , columns = ['UMAP component 1', 'UMAP component 2'])\n",
    "\n",
    "df_uh['sentence_id']=df_cluster.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128a19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "uh_cluster_assignment = cluster.labels_\n",
    "\n",
    "uh_cdf=pd.DataFrame(columns=[\"cluster_id\",\"sentence_id\",\"sentence\"])\n",
    "\n",
    "for i in range(len(uh_cluster_assignment)):\n",
    "    new_row=pd.Series(data={\"cluster_id\":uh_cluster_assignment[i],\n",
    "                                \"sentence_id\":i,\n",
    "                                \"sentence\":df_cluster.iloc[i]['original_text'],\n",
    "                                \"label\":df_cluster.iloc[i]['label'],\n",
    "                                \"err\":str(df_cluster.iloc[i]['err'])\n",
    "                           }\n",
    "                            )\n",
    "    uh_cdf=uh_cdf.append(new_row,ignore_index=True)\n",
    "\n",
    "uh_cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3440d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine PCA results with K-means results to see clustering\n",
    "df_uh_c=df_uh.merge(uh_cdf,right_on=['sentence_id'],left_on=['sentence_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c7cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_uh_c).mark_point(size=60).encode(\n",
    "    x='UMAP component 1',\n",
    "    y='UMAP component 2',\n",
    "    shape='err:N',\n",
    "    color=alt.Color('cluster_id', scale=alt.Scale(scheme='category20c')),\n",
    "    tooltip=['sentence','label']\n",
    ").properties(title='UMAP & HBDSCAN',height=400,width=500).interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b0806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uh_c[df_uh_c['sentence_id']==4257]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90052e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
