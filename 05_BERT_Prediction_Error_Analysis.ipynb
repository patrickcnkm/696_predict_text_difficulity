{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3c1e9a",
   "metadata": {},
   "source": [
    "# BERT Prediction Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64fc66",
   "metadata": {},
   "source": [
    "This code is used to:\n",
    "- Verify the impact from text preprocessing on BERT.\n",
    "- Utilize the unsupervised learning to look for the patterns of error data\n",
    "\n",
    "In order to speed up the issue analysis, only 1% of total training data(random sampling) is used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7d23c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Disable 3 types of warning\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\",category=(FutureWarning))\n",
    "warnings.filterwarnings(\"ignore\",category=(RuntimeWarning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffe1b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "import os\n",
    "from tqdm import trange\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from transformers import AdamW,get_linear_schedule_with_warmup\n",
    "from transformers import BertForSequenceClassification,DistilBertForSequenceClassification\n",
    "from transformers import BertTokenizer,DistilBertTokenizer\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29c3fa0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import helper functions\n",
    "\n",
    "from helper import train_dev_test, convert_examples_to_inputs,get_data_loader,data_evaluation,duple_labels,elbow_plot,train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7de7206",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Enable GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc24b893",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Enable logging.\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f401eebc",
   "metadata": {},
   "source": [
    "##### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a80adf3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# load train data\n",
    "source_train_data_path=\"./01_data/WikiLarge_Train.csv\"\n",
    "source_train_data=pd.read_csv(source_train_data_path)\n",
    "\n",
    "RANDOM_STATE=1\n",
    "PORTION=0.01\n",
    "size=round(len(source_train_data)*PORTION)\n",
    "train_data=source_train_data.sample(n=size,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91d20a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Plot histogram with the length. Truncate max length to 5000 tokens.\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "train_data['length'] = train_data['original_text'].apply(lambda x: len(x.split()))\n",
    "sns.distplot(train_data[train_data['length'] < 5000]['length'])\n",
    "plt.title('Frequence of sentences of a given length', fontsize=14)\n",
    "plt.xlabel('length', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99bcb0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT token length should not be more than 512.\n",
    "data_describe=train_data['original_text'].apply(lambda x: len(x.split())).describe()\n",
    "print(data_describe)\n",
    "MAX_SEQ_LENGTH=int(data_describe['max'])\n",
    "if MAX_SEQ_LENGTH>512:\n",
    "    MAX_SEQ_LENGTH=512"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce485e25",
   "metadata": {},
   "source": [
    "#### Verify the impact from text preprocessing\n",
    "\n",
    "The following situations will be considered respectively:\n",
    "- Initial status - Pretrain: evaluate the test dataset without training.\n",
    "- Fine tune without preprocessing: train the bert, then evaluate the test dataset.\n",
    "- Remove stopwords,train the bert, then evaluate the test dataset.\n",
    "- Correct mis-spelling,train the bert, then evaluate the test dataset.\n",
    "- Lemmanization,train the bert, then evaluate the test dataset.\n",
    "- Remove duplicate records (same label),train the bert, then evaluate the test dataset.\n",
    "- Remove duplicated records ( different label),train the bert, then evaluate the test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a472e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initalize the parameters for training / evaluation\n",
    "params={\n",
    "        \"GRADIENT_ACCUMULATION_STEPS\":1,\n",
    "        \"NUM_TRAIN_EPOCHS\":8,\n",
    "        \"LEARNING_RATE\":2e-5,\n",
    "        \"WARMUP_PROPORTION\":0.1,\n",
    "        \"MAX_GRAD_NORM\":5,\n",
    "        \"MAX_SEQ_LENGTH\":MAX_SEQ_LENGTH,\n",
    "        \"BATCH_SIZE\":16,\n",
    "        \"NUM_WARMUP_STEPS\":600\n",
    "}\n",
    "BERT_MODEL = \"distilbert-base-uncased\"\n",
    "OUTPUT_DIR = \"./tmp/\"\n",
    "MODEL_FILE_NAME = \"pytorch_model.bin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb83a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc=pd.DataFrame(columns=['description','accuracy','texts','labels','prediction'])\n",
    "list_acc=['Pretrain','Fine tune without preprocessing',\n",
    "                       'Removal of stopwords','Correction of spelling',\n",
    "                      'Lemmatization','Removal of duplicate records with same labels',\n",
    "                      'Removal of duplicate records with different labels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91937573",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_preprocessing import preprocess_text\n",
    "from text_preprocessing import check_spelling,remove_stopword,lemmatize_word\n",
    "\n",
    "for i in range(len(list_acc)):\n",
    "    ### prepare for data based on different situation\n",
    "    process_data=train_data.copy()\n",
    "    if list_acc[i]=='Removal of stopwords':\n",
    "        process_data['original_text'] = process_data['original_text'].apply(lambda x:' '.join(remove_stopword(x)))  \n",
    "    \n",
    "    if list_acc[i]=='Removal of stopwords':\n",
    "        process_data['original_text'] = process_data['original_text'].apply(lambda x:' '.join(check_spelling(x)) if type(x)=='str' else x) \n",
    "\n",
    "    if list_acc[i]=='Correction of spelling':\n",
    "        process_data['original_text'] = process_data['original_text'].apply(lambda x:' '.join(remove_stopword(x)))      \n",
    "       \n",
    "    if list_acc[i]=='Removal of duplicate records with same labels':\n",
    "        process_data.drop_duplicates(subset=['original_text','label'],inplace=True)\n",
    "\n",
    "    if list_acc[i]=='Removal of duplicate records with different labels':\n",
    "        # look for the records with different labels \n",
    "        df_2labels=process_data.copy()\n",
    "        df_duple_labels=duple_labels(df_2labels)\n",
    "        # Indentify double labels in data\n",
    "        df_2labels['duplicated']=df_2labels.duplicated(subset=['original_text'])\n",
    "        df_2labels=double_data_unique.merge(df_duple_labels,how=\"left\",left_on=\"original_text\",right_on=\"original_text\")\n",
    "        df_2labels['label_y']=df_2labels['label_y'].apply(lambda x: '0' if pd.isnull(x) else '1') # 0 means 1 label, 1 means 2 labels\n",
    "        df_2labels=pd.DataFrame(df_2labels[['original_text','label_x','label_y','duplicated']])\n",
    "        df_2labels.columns=['original_text','label','dulabel','duplicated']\n",
    "        process_data=df_2labels[df_2labels['dulabel']=='0'].copy()\n",
    "\n",
    "    _,(train_texts,dev_texts,test_texts),(train_labels,dev_labels,test_labels),\\\n",
    "                                        (target_names,label2idx)=train_dev_test(process_data,random_state=RANDOM_STATE)\n",
    "\n",
    "    ### Train model if it is not in \"pretrain\"\n",
    "    if list_acc[i]!='Pretrain':\n",
    "        train(BERT_MODEL,train_texts,train_labels,dev_texts,dev_labels,target_names,label2idx,params)\n",
    "        train_flag=True\n",
    "    else:\n",
    "        train_flag=False\n",
    "\n",
    "    ### Evaluate model\n",
    "    _,pred,acc=data_evaluation(test_texts,test_labels,BERT_MODEL,params,trained=train_flag,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)\n",
    "    \n",
    "    ### Save the output including dataset, accuracy results.\n",
    "    df_acc.at[i,'description']=list_acc[i]\n",
    "    df_acc.at[i,'accuracy']=acc\n",
    "    df_acc.at[i,'texts']=(train_texts,dev_texts,test_texts)\n",
    "    df_acc.at[i,'labels']=(train_labels,dev_labels,test_labels)\n",
    "    df_acc.at[i,'prediction']=pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b4cd993",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "bars = alt.Chart(df_acc).mark_bar().encode(\n",
    "    x='accuracy:Q',\n",
    "    y=\"description:O\"\n",
    ")\n",
    "\n",
    "text = bars.mark_text(\n",
    "    align='left',\n",
    "    baseline='middle',\n",
    "    dx=3  # Nudges text to right so it doesn't appear on top of the bar\n",
    ").encode(\n",
    "    text='accuracy:Q'\n",
    ")\n",
    "\n",
    "rule = alt.Chart(df_acc[df_acc['description']=='Pretrain']).mark_rule(color='red').encode(\n",
    "    y='accuracy:Q'\n",
    ")\n",
    "(bars + text + rule).properties(height=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ce95ae9",
   "metadata": {},
   "source": [
    "Compare the embeddings between error records in test set with training set + test set ( including error record), find out the similar \n",
    "records,display the numbers of different labels to check whether the portion of label could impact the classification records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f769ff43",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.DataFrame(columns=['original_text','label','err','init_pred','best_pred','cnt_1','cnt_0','avg_1','avg_0'])\n",
    "\n",
    "df_test['original_text']=orig_test_texts\n",
    "df_test['label']=orig_test_labels\n",
    "df_test['init_pred']=init_pred\n",
    "df_test['best_pred']=orig_pred\n",
    "df_test['err']=df_test['best_pred']-df_test['label']\n",
    "df_test['err']=df_test['err'].apply(lambda x: 1 if x!=0 else x)\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# work out the similarity and identify the record of self\n",
    "#str_to_predict=df_test['original_text'].iloc[11]\n",
    "#print(str_to_predict)\n",
    "query_embeddings=embedder.encode(df_test['original_text'])\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "onlinemodel='all-mpnet-base-v2'\n",
    "embedder = SentenceTransformer(onlinemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "068a98db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeec9f27",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train, dev, test data\n",
    "df_init,(train_texts,dev_texts,test_texts),(train_labels,dev_labels,test_labels),(target_names,label2idx)=train_dev_test(train_data,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40007d7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "daa5512b",
   "metadata": {},
   "source": [
    "##### Initial accuracy for pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a955d35",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,init_pred,init_acc=data_evaluation(test_texts,test_labels,BERT_MODEL,params,trained=False,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dce00c0",
   "metadata": {},
   "source": [
    "##### Train model without any preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa80ee52",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(BERT_MODEL,train_texts,train_labels,dev_texts,dev_labels,target_names,label2idx,params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9579a458",
   "metadata": {},
   "source": [
    "##### Accuracy after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825fd931",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,orig_pred,orig_acc=data_evaluation(test_texts,test_labels,BERT_MODEL,params,trained=True,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09cd12f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign those for future error analysis\n",
    "orig_train_texts,orig_train_labels=train_texts,train_labels\n",
    "orig_dev_texts,orig_dev_labels=dev_texts,dev_labels\n",
    "orig_test_texts,orig_test_labels=test_texts,test_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22951195",
   "metadata": {},
   "source": [
    "##### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653238e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocess text using custom preprocess functions in the pipeline \n",
    "#STOPWORDS=['-RRB-','-LRB-'] # remove customized stopwords\n",
    "#preprocess_functions = [to_lower, remove_punctuation,remove_special_character,normalize_unicode,remove_stopword,lemmatize_word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9990af42",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data=train_data.copy()\n",
    "process_data['original_text'] = process_data['original_text'].apply(lambda x:' '.join(remove_stopword(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf8bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb71c857",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sw,(train_texts,dev_texts,test_texts),(train_labels,dev_labels,test_labels),(target_names,label2idx)=train_dev_test(process_data,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62915432",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(BERT_MODEL,train_texts,train_labels,dev_texts,dev_labels,target_names,label2idx,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21b2c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,sw_pred,sw_acc=data_evaluation(test_texts,test_labels,BERT_MODEL,params,trained=True,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59bd3c90",
   "metadata": {},
   "source": [
    "##### Spelling correction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f37dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data=train_data.copy()\n",
    "process_data['original_text'] = process_data['original_text'].apply(lambda x:' '.join(check_spelling(x)) if type(x)=='str' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173b309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec7c355",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pc,(train_texts,dev_texts,test_texts),(train_labels,dev_labels,test_labels),(target_names,label2idx)=train_dev_test(process_data,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43fcbf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(BERT_MODEL,train_texts,train_labels,dev_texts,dev_labels,target_names,label2idx,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c15b007",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,pc_pred,pc_acc=data_evaluation(test_texts,test_labels,BERT_MODEL,params,trained=True,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2dc8007",
   "metadata": {},
   "source": [
    "##### Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b78c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data=train_data.copy()\n",
    "process_data['original_text'] = process_data['original_text'].apply(lambda x:' '.join(lemmatize_word(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd380f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data['original_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2dffd02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lm,(train_texts,dev_texts,test_texts),(train_labels,dev_labels,test_labels),(target_names,label2idx)=train_dev_test(process_data,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "174a5a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(BERT_MODEL,train_texts,train_labels,dev_texts,dev_labels,target_names,label2idx,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceb2278f",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,lm_pred,lm_acc=data_evaluation(test_texts,test_labels,BERT_MODEL,params,trained=True,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8bf41f",
   "metadata": {},
   "source": [
    "##### Check the duplicated data and create the data set without duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767783f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_unique=train_data.copy()\n",
    "train_data_unique['duplicated']=train_data_unique.duplicated(subset=['original_text'])\n",
    "#train_data_unique=train_data[train_data['duplicated']==False]\n",
    "#print(\"Duplicated records: %.2f%%\" %(100*(len(train_data)-len(train_data_unique))/len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f66e4835",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f5cc20",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data=train_data_unique.copy()\n",
    "process_data=process_data[(process_data['duplicated']==False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbf6f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dup,(train_texts,dev_texts,test_texts),(train_labels,dev_labels,test_labels),(target_names,label2idx)=train_dev_test(process_data,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c397613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(BERT_MODEL,train_texts,train_labels,dev_texts,dev_labels,target_names,label2idx,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f1c6c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,dup_pred,dup_acc=data_evaluation(test_texts,test_labels,BERT_MODEL,params,trained=True,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39051967",
   "metadata": {},
   "source": [
    "##### Remove the records which have the different labels\n",
    "The sentences with different labels should impact the train performance as well as prediction results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f886a9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for the records with different labels \n",
    "df_duple_labels=duple_labels(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3d15d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indentify double labels in data\n",
    "train_data_unique=train_data_unique.merge(df_duple_labels,how=\"left\",left_on=\"original_text\",right_on=\"original_text\")\n",
    "train_data_unique['label_y']=train_data_unique['label_y'].apply(lambda x: '0' if pd.isnull(x) else '1') # 0 means 1 label, 1 means 2 labels\n",
    "train_data_unique=pd.DataFrame(train_data_unique[['original_text','label_x','label_y','duplicated']])\n",
    "train_data_unique.columns=['original_text','label','dulabel','duplicated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25546482",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8326ebf4",
   "metadata": {},
   "source": [
    "##### Accuracy of removing records with duplicate text or different label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5660aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data=train_data_unique.copy()\n",
    "process_data=process_data[(process_data['dulabel']=='0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7dcb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc61e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_duo,(train_texts,dev_texts,test_texts),(train_labels,dev_labels,test_labels),(target_names,label2idx)=train_dev_test(process_data,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b9215c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(BERT_MODEL,train_texts,train_labels,dev_texts,dev_labels,target_names,label2idx,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f800100",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,duo_pred,duo_acc=data_evaluation(test_texts,test_labels,BERT_MODEL,params,trained=True,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78183ee2",
   "metadata": {},
   "source": [
    "##### Compare the results from different text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc7f0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc=pd.DataFrame(columns=['description','accuracy'])\n",
    "df_acc['description']=['Pretrain','Fine tune without preprocessing',\n",
    "                       'Removal of stopwords','Correction of spelling',\n",
    "                      'Lemmatization','Removal of duplicate records',\n",
    "                      'Removal of mislabeling']\n",
    "df_acc['accuracy']=[init_acc,orig_acc,sw_acc,pc_acc,lm_acc,dup_acc,duo_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ca85fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.barplot(data=df_acc, y=\"description\", x=\"accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83a0ccb2",
   "metadata": {},
   "source": [
    "##### Impact investigation on similar text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdd5154",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test=pd.DataFrame(columns=['original_text','label','err','init_pred','best_pred','cnt_1','cnt_0','avg_1','avg_0'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8585b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['original_text']=orig_test_texts\n",
    "df_test['label']=orig_test_labels\n",
    "df_test['init_pred']=init_pred\n",
    "df_test['best_pred']=orig_pred\n",
    "df_test['err']=df_test['best_pred']-df_test['label']\n",
    "df_test['err']=df_test['err'].apply(lambda x: 1 if x!=0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f2c56e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4b3d9f7",
   "metadata": {},
   "source": [
    "##### Display the length of test data and error data in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e599de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot histogram with the length. Truncate max length to 5000 tokens.\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "df_test['length'] = df_test['original_text'].apply(lambda x: len(x.split()))\n",
    "sns.distplot(df_test[df_test['length'] < 5000]['length'])\n",
    "plt.title('Frequence of sentences of a given length', fontsize=14)\n",
    "plt.xlabel('length', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ed60d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.distplot(df_test[(df_test['length'] < 5000) & (df_test['err']==1)]['length'])\n",
    "plt.title('Frequence of sentences of a given length', fontsize=14)\n",
    "plt.xlabel('length', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9eb464",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "onlinemodel='all-mpnet-base-v2'\n",
    "embedder = SentenceTransformer(onlinemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d2241a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "# work out the similarity and identify the record of self\n",
    "#str_to_predict=df_test['original_text'].iloc[11]\n",
    "#print(str_to_predict)\n",
    "query_embeddings=embedder.encode(df_test['original_text'])\n",
    "#sim=cosine_similarity([embedder.encode(str_to_predict)],query_embeddings)\n",
    "#j=np.argmax(sim)\n",
    "#sim.argsort()[-3:][::-1][0][:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a459ffc",
   "metadata": {},
   "source": [
    "Compare the embeddings between error records in test set with training set + test set ( including error record), find out the similar \n",
    "records,display the numbers of different labels to check whether the portion of label could impact the classification records."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed73410c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create the dataset for comparison,remove duplicate and different label\n",
    "#df_train=train_data_unique[(train_data_unique['duplicated']==False) | (train_data_unique['dulabel']=='0')]\n",
    "df_train=train_data_unique.copy()\n",
    "df_comp=pd.concat([pd.DataFrame(df_train[['original_text','label']]),pd.DataFrame()],\n",
    "                  ignore_index=True)\n",
    "\n",
    "#Assign the index to identify each row\n",
    "#df_comp=df_train.copy()\n",
    "df_comp=df_comp.reset_index()\n",
    "\n",
    "\n",
    "# Create the embedding for comparison dataset\n",
    "query_embeddings=embedder.encode(df_comp['original_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab673503",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['id']=df_test.index\n",
    "df_test['id']=df_test['id'].apply(lambda x: 'e'+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the simlarity threshold \n",
    "THRESHOLD=0.5\n",
    "\n",
    "#Create dateset to cluster the similar sentence\n",
    "err_cluster=pd.DataFrame(columns=list(df_comp.columns)+['score','cluster'])\n",
    "\n",
    "df_err=df_test[df_test['err']==1]\n",
    "for i in trange(len(df_err)):\n",
    "    #print(df_test[df_test['err']==1]['original_text'].iloc[i])\n",
    "    df_temp=pd.DataFrame(columns=err_cluster.columns)\n",
    "    str_to_predict=df_test[df_test['err']==1]['original_text'].iloc[i]\n",
    "    #print(str_to_predict)\n",
    "    sim=cosine_similarity([embedder.encode(str_to_predict)],query_embeddings)\n",
    "    j=np.argmax(sim)\n",
    "    sim_rows=list(np.where(sim[0]>THRESHOLD)[0])\n",
    "    if sim_rows !=[]:\n",
    "        #print(set(np.where(sim[0]>THRESHOLD)[0]))\n",
    "        \n",
    "        if err_cluster.empty:\n",
    "            df_temp=df_comp.iloc[sim_rows]\n",
    "        else:\n",
    "            #print(set(err_cluster['index']))\n",
    "            #df_temp=df_comp.iloc[list(set(sim_rows)-set(list(err_cluster['index'])))]\n",
    "            df_temp=df_comp.iloc[sim_rows]\n",
    "            # (df_temp)\n",
    "        \n",
    "        if df_temp.empty== False:\n",
    "            #print(sim[0][sim_rows])\n",
    "            df_temp['score']=sim[0][sim_rows]\n",
    "            df_temp['cluster']=df_err['id'].iloc[i]\n",
    "            \n",
    "            \n",
    "            err_cluster=pd.concat([err_cluster,df_temp],axis=0,ignore_index=True)\n",
    "            #print(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7b6c62e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test['id']=df_test.index\n",
    "df_test['id']=df_test['id'].apply(lambda x: 'e'+str(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f30372",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f043ede5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the simlarity threshold \n",
    "THRESHOLD=0.5\n",
    "\n",
    "#Create dateset to cluster the similar sentence\n",
    "err_cluster=pd.DataFrame(columns=list(df_comp.columns)+['score','cluster'])\n",
    "\n",
    "df_err=df_test[df_test['err']==1]\n",
    "for i in trange(len(df_err)):\n",
    "    #print(df_test[df_test['err']==1]['original_text'].iloc[i])\n",
    "    df_temp=pd.DataFrame(columns=err_cluster.columns)\n",
    "    str_to_predict=df_test[df_test['err']==1]['original_text'].iloc[i]\n",
    "    #print(str_to_predict)\n",
    "    sim=cosine_similarity([embedder.encode(str_to_predict)],query_embeddings)\n",
    "    j=np.argmax(sim)\n",
    "    sim_rows=list(np.where(sim[0]>THRESHOLD)[0])\n",
    "    if sim_rows !=[]:\n",
    "        #print(set(np.where(sim[0]>THRESHOLD)[0]))\n",
    "        \n",
    "        if err_cluster.empty:\n",
    "            df_temp=df_comp.iloc[sim_rows]\n",
    "        else:\n",
    "            #print(set(err_cluster['index']))\n",
    "            #df_temp=df_comp.iloc[list(set(sim_rows)-set(list(err_cluster['index'])))]\n",
    "            df_temp=df_comp.iloc[sim_rows]\n",
    "            # (df_temp)\n",
    "        \n",
    "        if df_temp.empty== False:\n",
    "            #print(sim[0][sim_rows])\n",
    "            df_temp['score']=sim[0][sim_rows]\n",
    "            df_temp['cluster']=df_err['id'].iloc[i]\n",
    "            \n",
    "            \n",
    "            err_cluster=pd.concat([err_cluster,df_temp],axis=0,ignore_index=True)\n",
    "            #print(df_temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a3593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35e06216",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display the records whose similar recods have 2 diferent labels\n",
    "df_group=err_cluster.groupby(['cluster','label']).count().reset_index().groupby('cluster').count()\n",
    "df_group[df_group['label']>1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14d47a8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_cluster[err_cluster['cluster']=='e100']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf298801",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err[df_err['id']=='e100']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ab38f65",
   "metadata": {},
   "source": [
    "Change label and retrain the model ,see whether it could impact the evluation result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce0b84da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create train, dev, test data\n",
    "df_comp.iloc[4088]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b30313fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.at[4088,'label']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1cc024",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.at[4088,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d791f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_text=df_comp['original_text']\n",
    "orig_train_label=df_comp['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5edb42f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(BERT_MODEL,orig_train_texts,orig_train_labels,orig_dev_texts,orig_dev_labels,target_names,label2idx,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88824f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,orig_pred,orig_acc=data_evaluation(orig_test_texts,orig_test_labels,BERT_MODEL,params,trained=True,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4523835c",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_test_texts[100],orig_pred[100]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c27505",
   "metadata": {},
   "source": [
    "Apparently, after chaning one record's label from 1 to 0, the result of evaluation is changed as well.\n",
    "Let's change the label back, and take further test again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7589057b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.at[4088,'label']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64cc9427",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.at[4088,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d272ea9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_cluster[err_cluster['cluster']=='e9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2a26e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err[df_err['id']=='e9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc522e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.at[3467,'label']=0\n",
    "df_comp.at[642,'label']=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7a9d0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comp.at[3467,'label'],df_comp.at[642,'label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94d06a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_train_text=df_comp['original_text']\n",
    "orig_train_label=df_comp['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29617a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train(BERT_MODEL,orig_train_texts,orig_train_labels,orig_dev_texts,orig_dev_labels,target_names,label2idx,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cabef8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "_,orig_pred,orig_acc=data_evaluation(orig_test_texts,orig_test_labels,BERT_MODEL,params,trained=True,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d3661e",
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_test_texts[9],orig_pred[9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f492b2c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9eeeba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_cluster[err_cluster['cluster']=='e103']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcad0d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err[df_err['id']=='e103']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9cbfcf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_cluster[err_cluster['cluster']=='e111']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a227c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_err[df_err['id']=='e111']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ab05ab",
   "metadata": {},
   "source": [
    "##### Final report 5.3 - Unsupervised learning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881744b1",
   "metadata": {},
   "source": [
    "Step 1. Create dataset for unsupervised learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2bfed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the embedding for comparison dataset\n",
    "df_train=train_data_unique.copy()\n",
    "df_train['type']='train'\n",
    "df_train['err']='0'\n",
    "df_test['type']='test'\n",
    "df_cluster=pd.concat([pd.DataFrame(df_train[['original_text','label','type','err']]),\n",
    "                   pd.DataFrame(df_test[['original_text','label','type','err']])],\n",
    "                  ignore_index=True)\n",
    "\n",
    "#Assign the index to identify each row\n",
    "df_cluster=df_cluster.reset_index()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92ed1443",
   "metadata": {},
   "source": [
    "Step 2. Using sentence-BERT to create the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "859dda3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_embeddings=embedder.encode(df_cluster['original_text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d65885c",
   "metadata": {},
   "source": [
    "Step 3. Run PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4109f2f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering algorithms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Using PCA to reduce the dimension to project the result to 2-d scatter plot\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(cluster_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886fb438",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "df_pca['sentence_id']=df_cluster.index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82dabdd3",
   "metadata": {},
   "source": [
    "Step 4. Run Elbow method to find out optimal K."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64b04e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Elbow for full training data\n",
    "elbow_plot(principalComponents,maxK=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85959e16",
   "metadata": {},
   "source": [
    "Step 5. Run Kmeans to cluster the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d523da",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 2\n",
    "clf = KMeans(n_clusters=num_clusters, \n",
    "            max_iter=100, \n",
    "            init='k-means++', \n",
    "            n_init=1)\n",
    "clf.fit_predict(cluster_embeddings)\n",
    "cluster_assignment = clf.labels_\n",
    "\n",
    "cdf=pd.DataFrame(columns=[\"cluster_id\",\"sentence_id\",\"sentence\"])\n",
    "\n",
    "for i in range(len(cluster_assignment)):\n",
    "    new_row=pd.Series(data={\"cluster_id\":cluster_assignment[i],\n",
    "                                \"sentence_id\":i,\n",
    "                                \"sentence\":df_cluster.iloc[i]['original_text'],\n",
    "                                \"label\":df_cluster.iloc[i]['label'],\n",
    "                                \"err\":str(df_cluster.iloc[i]['err'])\n",
    "                           }\n",
    "                            )\n",
    "    cdf=cdf.append(new_row,ignore_index=True)\n",
    "\n",
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fcd4879",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine PCA results with K-means results to see clustering\n",
    "df_k=df_pca.merge(cdf,right_on=['sentence_id'],left_on=['sentence_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f2a6cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14e72aa",
   "metadata": {},
   "source": [
    "Step 6. Plot clustering results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb7ae59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import altair as alt\n",
    "\n",
    "alt.Chart(df_k).mark_point(size=60).encode(\n",
    "    x='principal component 1',\n",
    "    y='principal component 2',\n",
    "    shape='err:N',\n",
    "    color=alt.Color('cluster_id', scale=alt.Scale(scheme='category20c')),\n",
    "    tooltip=['sentence','sentence_id','label']\n",
    ").properties(title='PCA & Kmeans',height=400,width=500).interactive()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ffdf35cc",
   "metadata": {},
   "source": [
    "Using UMAP & HDBSCAN  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53d26170",
   "metadata": {},
   "outputs": [],
   "source": [
    "import umap\n",
    "umap_embeddings = umap.UMAP(n_neighbors=30, \n",
    "                            n_components=2, \n",
    "                            metric='cosine').fit_transform(cluster_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "175351bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import hdbscan\n",
    "cluster = hdbscan.HDBSCAN(min_cluster_size=2,\n",
    "                          metric='euclidean',                      \n",
    "                          cluster_selection_method='eom').fit(umap_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bc88e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "umap_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689ea577",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uh = pd.DataFrame(data = umap_embeddings\n",
    "             , columns = ['UMAP component 1', 'UMAP component 2'])\n",
    "\n",
    "df_uh['sentence_id']=df_cluster.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128a19cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "uh_cluster_assignment = cluster.labels_\n",
    "\n",
    "uh_cdf=pd.DataFrame(columns=[\"cluster_id\",\"sentence_id\",\"sentence\"])\n",
    "\n",
    "for i in range(len(uh_cluster_assignment)):\n",
    "    new_row=pd.Series(data={\"cluster_id\":uh_cluster_assignment[i],\n",
    "                                \"sentence_id\":i,\n",
    "                                \"sentence\":df_cluster.iloc[i]['original_text'],\n",
    "                                \"label\":df_cluster.iloc[i]['label'],\n",
    "                                \"err\":str(df_cluster.iloc[i]['err'])\n",
    "                           }\n",
    "                            )\n",
    "    uh_cdf=uh_cdf.append(new_row,ignore_index=True)\n",
    "\n",
    "uh_cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3440d5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine PCA results with K-means results to see clustering\n",
    "df_uh_c=df_uh.merge(uh_cdf,right_on=['sentence_id'],left_on=['sentence_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86c7cf92",
   "metadata": {},
   "outputs": [],
   "source": [
    "alt.Chart(df_uh_c).mark_point(size=60).encode(\n",
    "    x='UMAP component 1',\n",
    "    y='UMAP component 2',\n",
    "    shape='err:N',\n",
    "    color=alt.Color('cluster_id', scale=alt.Scale(scheme='category20c')),\n",
    "    tooltip=['sentence','label']\n",
    ").properties(title='UMAP & HBDSCAN',height=400,width=500).interactive()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b0806f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_uh_c[df_uh_c['sentence_id']==4257]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90052e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
