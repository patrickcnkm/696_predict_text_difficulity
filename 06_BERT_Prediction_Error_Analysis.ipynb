{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3c1e9a",
   "metadata": {},
   "source": [
    "# BERT Prediction Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64fc66",
   "metadata": {},
   "source": [
    "As the result of text classification by 3 types of BERT models ( BERT_BASED_UNCASED, BERT_LARGE_UNCASED, DISTILBERT), it is found that:\n",
    " - The smaller the model is, the higher the accuracies. Distilbert achieved 77.8% in contrast that Bert_large_uncased only achieved 70& around.\n",
    "\n",
    "In order to improve the accuracy level, we will perform the further study on those records whose prediction result are wrong, and see whether there are some ways.\n",
    "\n",
    "Given Bert_large_uncased does not achieved high accuracy, in order to save the potential efforts, we take the remaining 2 models for the error analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb7d23c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Disable 3 types of warning\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\",category=(FutureWarning))\n",
    "warnings.filterwarnings(\"ignore\",category=(RuntimeWarning))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb206c6e",
   "metadata": {},
   "source": [
    "##### import error data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "511de07e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import bert error data\n",
    "error_data_0_path=\"./tmp/test_error2022-09-29.csv\"\n",
    "error_data_0=pd.read_csv(error_data_0_path)\n",
    "# import distilbert data\n",
    "error_data_1_path=\"./tmp/test_error_distillbert_2022-10-06.csv\"\n",
    "error_data_1=pd.read_csv(error_data_1_path)\n",
    "\n",
    "# Pick up the common error data\n",
    "error_data=error_data_1.merge(right=error_data_0,how=\"inner\",on=['original_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f248fba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>original_text</th>\n",
       "      <th>label_x</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>label_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Military bases Virginia Beach is home to sever...</td>\n",
       "      <td>0</td>\n",
       "      <td>932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>The success of the first event enabled its pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>4361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>In 1963 , the CMA announced that a Country Mus...</td>\n",
       "      <td>1</td>\n",
       "      <td>2691</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>URM.edu</td>\n",
       "      <td>1</td>\n",
       "      <td>1698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>FlÃ rez was married to German-born Julia Trapp...</td>\n",
       "      <td>0</td>\n",
       "      <td>9366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0_x                                      original_text  label_x  \\\n",
       "0             2  Military bases Virginia Beach is home to sever...        0   \n",
       "1             9  The success of the first event enabled its pro...        0   \n",
       "2            13  In 1963 , the CMA announced that a Country Mus...        1   \n",
       "3            28                                            URM.edu        1   \n",
       "4            41  FlÃ rez was married to German-born Julia Trapp...        0   \n",
       "\n",
       "   Unnamed: 0_y  label_y  \n",
       "0           932        0  \n",
       "1          4361        0  \n",
       "2          2691        1  \n",
       "3          1698        1  \n",
       "4          9366        0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "409061c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Distribution of original text length in words')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# TRAIN SET \n",
    "error_data['original_text'].apply(lambda x: len(x.split())).plot(kind='hist');\n",
    "plt.yscale('log');\n",
    "plt.title('Distribution of original text length in words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "554f9032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1009.000000\n",
       "mean       20.440040\n",
       "std        12.881813\n",
       "min         1.000000\n",
       "25%        12.000000\n",
       "50%        19.000000\n",
       "75%        27.000000\n",
       "max        80.000000\n",
       "Name: original_text, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_data['original_text'].apply(lambda x: len(x.split())).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6ad857e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>original_text</th>\n",
       "      <th>label_x</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>label_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Military bases Virginia Beach is home to sever...</td>\n",
       "      <td>0</td>\n",
       "      <td>932</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>The success of the first event enabled its pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>4361</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>In 1963 , the CMA announced that a Country Mus...</td>\n",
       "      <td>1</td>\n",
       "      <td>2691</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>URM.edu</td>\n",
       "      <td>1</td>\n",
       "      <td>1698</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>FlÃ rez was married to German-born Julia Trapp...</td>\n",
       "      <td>0</td>\n",
       "      <td>9366</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>9544</td>\n",
       "      <td>She grew up in Basildon , where she attended s...</td>\n",
       "      <td>0</td>\n",
       "      <td>4234</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>9548</td>\n",
       "      <td>Its official nickname is the '' Socceroos '' .</td>\n",
       "      <td>1</td>\n",
       "      <td>3170</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>9551</td>\n",
       "      <td>In late 1990 , shortly after the band 's first...</td>\n",
       "      <td>0</td>\n",
       "      <td>7747</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>9590</td>\n",
       "      <td>The language is thousand 's of years old .</td>\n",
       "      <td>1</td>\n",
       "      <td>10278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>9599</td>\n",
       "      <td>In a few special cases , an unreleased album m...</td>\n",
       "      <td>0</td>\n",
       "      <td>6584</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0_x                                      original_text  \\\n",
       "0                2  Military bases Virginia Beach is home to sever...   \n",
       "1                9  The success of the first event enabled its pro...   \n",
       "2               13  In 1963 , the CMA announced that a Country Mus...   \n",
       "3               28                                            URM.edu   \n",
       "4               41  FlÃ rez was married to German-born Julia Trapp...   \n",
       "...            ...                                                ...   \n",
       "1004          9544  She grew up in Basildon , where she attended s...   \n",
       "1005          9548     Its official nickname is the '' Socceroos '' .   \n",
       "1006          9551  In late 1990 , shortly after the band 's first...   \n",
       "1007          9590         The language is thousand 's of years old .   \n",
       "1008          9599  In a few special cases , an unreleased album m...   \n",
       "\n",
       "      label_x  Unnamed: 0_y  label_y  \n",
       "0           0           932        0  \n",
       "1           0          4361        0  \n",
       "2           1          2691        1  \n",
       "3           1          1698        1  \n",
       "4           0          9366        0  \n",
       "...       ...           ...      ...  \n",
       "1004        0          4234        0  \n",
       "1005        1          3170        1  \n",
       "1006        0          7747        0  \n",
       "1007        1         10278        1  \n",
       "1008        0          6584        0  \n",
       "\n",
       "[1009 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9ece0e",
   "metadata": {},
   "source": [
    "### Rerun the prediction to confirm the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1e596fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "#MAX_SEQ_LENGTH=100\n",
    "MAX_SEQ_LENGTH=80\n",
    "\n",
    "class BertInputItem(object):\n",
    "    \"\"\"An item with all the necessary attributes for finetuning BERT.\"\"\"\n",
    "\n",
    "    def __init__(self, text, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.text = text\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        \n",
    "\n",
    "def convert_examples_to_inputs(example_texts, example_labels, label2idx, max_seq_length, tokenizer):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    \n",
    "    input_items = []\n",
    "    examples = zip(example_texts, example_labels)\n",
    "    for (ex_index, (text, label)) in enumerate(examples):\n",
    "\n",
    "        # Create a list of token ids\n",
    "        input_ids = tokenizer.encode(f\"[CLS] {text} [SEP]\")\n",
    "        if len(input_ids) > max_seq_length:\n",
    "            input_ids = input_ids[:max_seq_length]\n",
    "\n",
    "        # All our tokens are in the first input segment (id 0).\n",
    "        segment_ids = [0] * len(input_ids)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        label_id = label2idx[label]\n",
    "\n",
    "        input_items.append(\n",
    "            BertInputItem(text=text,\n",
    "                          input_ids=input_ids,\n",
    "                          input_mask=input_mask,\n",
    "                          segment_ids=segment_ids,\n",
    "                          label_id=label_id))\n",
    "\n",
    "        \n",
    "    return input_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ff48147e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "\n",
    "def get_data_loader(features, max_seq_length, batch_size, shuffle=True): \n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "\n",
    "    #dataloader = DataLoader(data, shuffle=shuffle, batch_size=batch_size)\n",
    "    # dataloader tuning in https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html\n",
    "   \n",
    "    dataloader = DataLoader(data, shuffle=shuffle, batch_size=batch_size,num_workers=2,pin_memory=True)\n",
    "    return dataloader\n",
    "\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "33b1ab8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    predicted_labels, correct_labels = [], []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(dataloader, desc=\"Evaluation iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            #tmp_eval_loss, logits = model(input_ids, attention_mask=input_mask,\n",
    "            #                              token_type_ids=segment_ids, labels=label_ids)[:2]\n",
    "            tmp_eval_loss, logits = model(input_ids, attention_mask=input_mask,\n",
    "                                         labels=label_ids)[:2]  # for distilbert\n",
    "        outputs = np.argmax(logits.to('cpu'), axis=1)\n",
    "        label_ids = label_ids.to('cpu').numpy()\n",
    "        \n",
    "        predicted_labels += list(outputs)\n",
    "        correct_labels += list(label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    \n",
    "    correct_labels = np.array(correct_labels)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "        \n",
    "    return eval_loss, correct_labels, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fd228c55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertForSequenceClassification,DistilBertForSequenceClassification\n",
    "from transformers import BertTokenizer,DistilBertTokenizer\n",
    "import os\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "# Evaluate the dataset based on trained distilbert model\n",
    "def data_evaluation(texts,labels,OUTPUT_DIR = \"./tmp/\", MODEL_FILE_NAME = \"pytorch_model.bin\"):\n",
    "    # Convert test data of submission to features\n",
    "    target_names = list(set(labels))\n",
    "    label2idx = {label: idx for idx, label in enumerate(target_names)}\n",
    "    \n",
    "    # Enable GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Select bert model\n",
    "    BERT_MODEL = \"distilbert-base-uncased\"\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(BERT_MODEL)\n",
    "    \n",
    "    # Using trained model\n",
    "    model_state_dict = torch.load(os.path.join(OUTPUT_DIR, MODEL_FILE_NAME), map_location=lambda storage, loc: storage)\n",
    "    model=DistilBertForSequenceClassification.from_pretrained(BERT_MODEL, state_dict=model_state_dict, num_labels = len(target_names),\n",
    "                                                              ignore_mismatched_sizes=True)\n",
    "    model.to(device)\n",
    "    \n",
    "    # Convert text and labels to embeddings \n",
    "    features = convert_examples_to_inputs(texts, labels, label2idx, MAX_SEQ_LENGTH, tokenizer)\n",
    "    dataloader = get_data_loader(features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Predict the result, and discard the evaluatoin result, only take the prediction result.\n",
    "    _, correct, predicted = evaluate(model, dataloader)\n",
    "    print(\"Errors performance:\", precision_recall_fscore_support(correct, predicted, average=\"micro\"))\n",
    "\n",
    "    #bert_accuracy = np.mean(predicted == correct)\n",
    "    \n",
    "    #print(bert_accuracy)\n",
    "    print(classification_report(correct, predicted))\n",
    "\n",
    "    return correct,predicted "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dda16ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e17c4dbf2a4148a17f214d3d071f1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors performance: (0.0, 0.0, 0.0, None)\n",
      "0.0\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00     714.0\n",
      "           1       0.00      0.00      0.00     295.0\n",
      "\n",
      "    accuracy                           0.00    1009.0\n",
      "   macro avg       0.00      0.00      0.00    1009.0\n",
      "weighted avg       0.00      0.00      0.00    1009.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, ..., 0, 1, 0], dtype=int64),\n",
       " array([1, 1, 0, ..., 1, 0, 1], dtype=int64))"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm the error data should not be predicted correctly.\n",
    "texts=list(error_data[\"original_text\"])\n",
    "labels=list(error_data[\"label_x\"])\n",
    "data_evaluation(texts,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb35efd3",
   "metadata": {},
   "source": [
    "#### Spelling error correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "78a15ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct spelling error to check whether accuracy could be improved.\n",
    "from textblob import TextBlob\n",
    "error_data['correct_text_0'] = error_data['original_text'].apply(lambda x :TextBlob(x).correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "0819fc8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9312113ff59b4b32b70835113e3882b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors performance: (0.0981169474727453, 0.0981169474727453, 0.0981169474727453, None)\n",
      "0.0981169474727453\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.25      0.13      0.17       714\n",
      "           1       0.00      0.01      0.01       295\n",
      "\n",
      "    accuracy                           0.10      1009\n",
      "   macro avg       0.13      0.07      0.09      1009\n",
      "weighted avg       0.18      0.10      0.13      1009\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, ..., 0, 1, 0], dtype=int64),\n",
       " array([0, 1, 0, ..., 1, 0, 1], dtype=int64))"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts=list(error_data[\"correct_text_0\"])\n",
    "labels=list(error_data[\"label_x\"])\n",
    "data_evaluation(texts,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6943046d",
   "metadata": {},
   "source": [
    "##### The above result suggests spelling check could improve 13% accuracy, however, the performance of spelling check is not encouraging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "def19571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#error_data.to_csv(\"./tmp/error_data_20221006.csv\",index=False) # export error data to csv for manual check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e097188d",
   "metadata": {},
   "source": [
    "#### Clean text to see whether that would improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "cf439c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "def clean_text(text):\n",
    "    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n",
    "    and remove words containing numbers.'''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "dd3d2640",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_data['clean_text'] = error_data['original_text'].apply(lambda x:clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a4f8dd67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b86bf2f464e4d8d986224c505b3e960",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors performance: (0.2556987115956392, 0.2556987115956392, 0.2556987115956392, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.46      0.33      0.39       714\n",
      "           1       0.04      0.07      0.05       295\n",
      "\n",
      "    accuracy                           0.26      1009\n",
      "   macro avg       0.25      0.20      0.22      1009\n",
      "weighted avg       0.34      0.26      0.29      1009\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, ..., 0, 1, 0], dtype=int64),\n",
       " array([1, 1, 0, ..., 0, 0, 1], dtype=int64))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts=list(error_data[\"clean_text\"])\n",
    "labels=list(error_data[\"label_x\"])\n",
    "data_evaluation(texts,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "345b5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_preprocessing import preprocess_text\n",
    "from text_preprocessing import to_lower, remove_punctuation,remove_special_character,normalize_unicode,check_spelling,remove_stopword,lemmatize_word\n",
    "# Preprocess text using custom preprocess functions in the pipeline \n",
    "STOPWORDS=['-RRB-','-LRB-'] # remove customized stopwords\n",
    "preprocess_functions = [to_lower, remove_punctuation,remove_special_character,normalize_unicode,remove_stopword,lemmatize_word]\n",
    "error_data['preprocess_text'] = error_data['original_text'].apply(lambda x:' '.join(remove_stopword(preprocess_text(x,preprocess_functions),\n",
    "                                                                                          stop_words=STOPWORDS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "c2502970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>original_text</th>\n",
       "      <th>label_x</th>\n",
       "      <th>Unnamed: 0_y</th>\n",
       "      <th>label_y</th>\n",
       "      <th>correct_text_0</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>preprocess_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Military bases Virginia Beach is home to sever...</td>\n",
       "      <td>0</td>\n",
       "      <td>932</td>\n",
       "      <td>0</td>\n",
       "      <td>(M, i, l, i, t, a, r, y,  , b, a, s, e, s,  , ...</td>\n",
       "      <td>military bases virginia beach is home to sever...</td>\n",
       "      <td>military base virginia beach home several unit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>The success of the first event enabled its pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>4361</td>\n",
       "      <td>0</td>\n",
       "      <td>(T, h, e,  , s, u, c, c, e, s, s,  , o, f,  , ...</td>\n",
       "      <td>the success of the first event enabled its pro...</td>\n",
       "      <td>success first event enabled promoter hold regu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>13</td>\n",
       "      <td>In 1963 , the CMA announced that a Country Mus...</td>\n",
       "      <td>1</td>\n",
       "      <td>2691</td>\n",
       "      <td>1</td>\n",
       "      <td>(I, n,  , 1, 9, 6, 3,  , ,,  , t, h, e,  , C, ...</td>\n",
       "      <td>in   the cma announced that a country music ha...</td>\n",
       "      <td>1963 cma announced country music hall fame mus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>28</td>\n",
       "      <td>URM.edu</td>\n",
       "      <td>1</td>\n",
       "      <td>1698</td>\n",
       "      <td>1</td>\n",
       "      <td>(U, R, M, ., e, d)</td>\n",
       "      <td>urmedu</td>\n",
       "      <td>urmedu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>41</td>\n",
       "      <td>FlÃ rez was married to German-born Julia Trapp...</td>\n",
       "      <td>0</td>\n",
       "      <td>9366</td>\n",
       "      <td>0</td>\n",
       "      <td>(a, l, l,  , r, e, d,  , w, a, s,  , m, a, r, ...</td>\n",
       "      <td>flã rez was married to germanborn julia trappe...</td>\n",
       "      <td>fla rez married germanborn julia trappe privat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>9544</td>\n",
       "      <td>She grew up in Basildon , where she attended s...</td>\n",
       "      <td>0</td>\n",
       "      <td>4234</td>\n",
       "      <td>0</td>\n",
       "      <td>(T, h, e,  , g, r, e, w,  , u, p,  , i, n,  , ...</td>\n",
       "      <td>she grew up in basildon  where she attended sc...</td>\n",
       "      <td>grew basildon attended school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>9548</td>\n",
       "      <td>Its official nickname is the '' Socceroos '' .</td>\n",
       "      <td>1</td>\n",
       "      <td>3170</td>\n",
       "      <td>1</td>\n",
       "      <td>(I, t, s,  , o, f, f, i, c, i, a, l,  , n, i, ...</td>\n",
       "      <td>its official nickname is the  socceroos</td>\n",
       "      <td>official nickname socceroos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1006</th>\n",
       "      <td>9551</td>\n",
       "      <td>In late 1990 , shortly after the band 's first...</td>\n",
       "      <td>0</td>\n",
       "      <td>7747</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, n,  , l, a, t, e,  , 1, 9, 9, 0,  , ,,  , ...</td>\n",
       "      <td>in late   shortly after the band s first world...</td>\n",
       "      <td>late 1990 shortly band first worldwide tour so...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1007</th>\n",
       "      <td>9590</td>\n",
       "      <td>The language is thousand 's of years old .</td>\n",
       "      <td>1</td>\n",
       "      <td>10278</td>\n",
       "      <td>1</td>\n",
       "      <td>(T, h, e,  , l, a, n, g, u, a, g, e,  , i, s, ...</td>\n",
       "      <td>the language is thousand s of years old</td>\n",
       "      <td>language thousand year old</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1008</th>\n",
       "      <td>9599</td>\n",
       "      <td>In a few special cases , an unreleased album m...</td>\n",
       "      <td>0</td>\n",
       "      <td>6584</td>\n",
       "      <td>0</td>\n",
       "      <td>(I, n,  , a,  , f, e, w,  , s, p, e, c, i, a, ...</td>\n",
       "      <td>in a few special cases  an unreleased album ma...</td>\n",
       "      <td>special case unreleased album may meet guideli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1009 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0_x                                      original_text  \\\n",
       "0                2  Military bases Virginia Beach is home to sever...   \n",
       "1                9  The success of the first event enabled its pro...   \n",
       "2               13  In 1963 , the CMA announced that a Country Mus...   \n",
       "3               28                                            URM.edu   \n",
       "4               41  FlÃ rez was married to German-born Julia Trapp...   \n",
       "...            ...                                                ...   \n",
       "1004          9544  She grew up in Basildon , where she attended s...   \n",
       "1005          9548     Its official nickname is the '' Socceroos '' .   \n",
       "1006          9551  In late 1990 , shortly after the band 's first...   \n",
       "1007          9590         The language is thousand 's of years old .   \n",
       "1008          9599  In a few special cases , an unreleased album m...   \n",
       "\n",
       "      label_x  Unnamed: 0_y  label_y  \\\n",
       "0           0           932        0   \n",
       "1           0          4361        0   \n",
       "2           1          2691        1   \n",
       "3           1          1698        1   \n",
       "4           0          9366        0   \n",
       "...       ...           ...      ...   \n",
       "1004        0          4234        0   \n",
       "1005        1          3170        1   \n",
       "1006        0          7747        0   \n",
       "1007        1         10278        1   \n",
       "1008        0          6584        0   \n",
       "\n",
       "                                         correct_text_0  \\\n",
       "0     (M, i, l, i, t, a, r, y,  , b, a, s, e, s,  , ...   \n",
       "1     (T, h, e,  , s, u, c, c, e, s, s,  , o, f,  , ...   \n",
       "2     (I, n,  , 1, 9, 6, 3,  , ,,  , t, h, e,  , C, ...   \n",
       "3                                    (U, R, M, ., e, d)   \n",
       "4     (a, l, l,  , r, e, d,  , w, a, s,  , m, a, r, ...   \n",
       "...                                                 ...   \n",
       "1004  (T, h, e,  , g, r, e, w,  , u, p,  , i, n,  , ...   \n",
       "1005  (I, t, s,  , o, f, f, i, c, i, a, l,  , n, i, ...   \n",
       "1006  (I, n,  , l, a, t, e,  , 1, 9, 9, 0,  , ,,  , ...   \n",
       "1007  (T, h, e,  , l, a, n, g, u, a, g, e,  , i, s, ...   \n",
       "1008  (I, n,  , a,  , f, e, w,  , s, p, e, c, i, a, ...   \n",
       "\n",
       "                                             clean_text  \\\n",
       "0     military bases virginia beach is home to sever...   \n",
       "1     the success of the first event enabled its pro...   \n",
       "2     in   the cma announced that a country music ha...   \n",
       "3                                                urmedu   \n",
       "4     flã rez was married to germanborn julia trappe...   \n",
       "...                                                 ...   \n",
       "1004  she grew up in basildon  where she attended sc...   \n",
       "1005          its official nickname is the  socceroos     \n",
       "1006  in late   shortly after the band s first world...   \n",
       "1007           the language is thousand s of years old    \n",
       "1008  in a few special cases  an unreleased album ma...   \n",
       "\n",
       "                                        preprocess_text  \n",
       "0     military base virginia beach home several unit...  \n",
       "1     success first event enabled promoter hold regu...  \n",
       "2     1963 cma announced country music hall fame mus...  \n",
       "3                                                urmedu  \n",
       "4     fla rez married germanborn julia trappe privat...  \n",
       "...                                                 ...  \n",
       "1004                      grew basildon attended school  \n",
       "1005                        official nickname socceroos  \n",
       "1006  late 1990 shortly band first worldwide tour so...  \n",
       "1007                         language thousand year old  \n",
       "1008  special case unreleased album may meet guideli...  \n",
       "\n",
       "[1009 rows x 8 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "b5add739",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e03191016ca1428cbe26a544bd11a9d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors performance: (0.4132804757185332, 0.4132804757185332, 0.41328047571853316, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.53      0.56       714\n",
      "           1       0.10      0.13      0.12       295\n",
      "\n",
      "    accuracy                           0.41      1009\n",
      "   macro avg       0.35      0.33      0.34      1009\n",
      "weighted avg       0.45      0.41      0.43      1009\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0, 0, 1, ..., 0, 1, 0], dtype=int64),\n",
       " array([0, 0, 0, ..., 0, 0, 1], dtype=int64))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts=list(error_data[\"preprocess_text\"])\n",
    "labels=list(error_data[\"label_x\"])\n",
    "data_evaluation(texts,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b243c6f",
   "metadata": {},
   "source": [
    "#### The accuracy of error list was improved to 45%, and it looks like the preprocessing text do help to improve accuracy. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7692f39f",
   "metadata": {},
   "source": [
    "##### Given the above improvement, and try to apply this to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a8325e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the test data for submission\n",
    "sub_data_path=\"./01_data/WikiLarge_Test.csv\"\n",
    "sub_data=pd.read_csv(sub_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "aee62584",
   "metadata": {},
   "outputs": [],
   "source": [
    " sub_data['original_text'] = sub_data['original_text'].apply(lambda x:' '.join(remove_stopword(preprocess_text(x,preprocess_functions),\n",
    "                                                                                          stop_words=STOPWORDS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "e17289bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission Test size: 119092\n"
     ]
    }
   ],
   "source": [
    "sub_texts=list(sub_data[\"original_text\"])\n",
    "sub_labels=[1 for i in range(len(sub_texts))]\n",
    "\n",
    "print(\"Submission Test size:\", len(sub_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "82aa4915",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized because the shapes did not match:\n",
      "- classifier.weight: found shape torch.Size([2, 768]) in the checkpoint and torch.Size([1, 768]) in the model instantiated\n",
      "- classifier.bias: found shape torch.Size([2]) in the checkpoint and torch.Size([1]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82bdfcdec3a440b49f20da4d9a93874e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/7444 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors performance: (1.0, 1.0, 1.0, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00    119092\n",
      "\n",
      "    accuracy                           1.00    119092\n",
      "   macro avg       1.00      1.00      1.00    119092\n",
      "weighted avg       1.00      1.00      1.00    119092\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_, sub_predicted=data_evaluation(sub_texts,sub_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "00ce1271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the submission file\n",
    "df_sub=pd.DataFrame(columns=[\"id\",\"label\"])\n",
    "df_sub['label']=sub_predicted\n",
    "df_sub['id']=[i for i in range(len(sub_predicted))]\n",
    "df_sub.to_csv(\"./tmp/submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469e40c0",
   "metadata": {},
   "source": [
    "### Embedding-based clustering analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0b04163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other utils\n",
    "from tqdm import tqdm  # Progress bar\n",
    "# Transformers\n",
    "from transformers import pipeline\n",
    "import ipywidgets as widgets\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b6c4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onlinemodel='distiluse-base-multilingual-cased-v2'\n",
    "onlinemodel=\"all-mpnet-base-v2\"\n",
    "embedder = SentenceTransformer(onlinemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359c7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries= list(error_data['original_text'])\n",
    "query_embeddings=embedder.encode(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Elbow criterion - Determine optimal numbers of clusters by elbow rule.\n",
    "def elbow_plot(data, maxK=15, seed_centroids=None):\n",
    "    \"\"\"\n",
    "        parameters:\n",
    "        - data: pandas DataFrame (data to be fitted)\n",
    "        - maxK (default = 10): integer (maximum number of clusters with which to run k-means)\n",
    "        - seed_centroids (default = None ): float (initial value of centroids for k-means)\n",
    "    \"\"\"\n",
    "    sse = []\n",
    "    K= range(1, maxK)\n",
    "    for k in K:\n",
    "        if seed_centroids is not None:\n",
    "            seeds = seed_centroids.head(k)\n",
    "            kmeans = KMeans(n_clusters=k, max_iter=500, n_init=100, random_state=0, init=np.reshape(seeds, (k,1))).fit(data)\n",
    "            #data[\"clusters\"] = kmeans.labels_\n",
    "        else:\n",
    "            kmeans = KMeans(n_clusters=k, max_iter=300, n_init=100, random_state=0).fit(data)\n",
    "            #data[\"clusters\"] = kmeans.labels_\n",
    "        print(\"k: \", k,\"sse: \",kmeans.inertia_)\n",
    "        # Inertia: Sum of distances of samples to their closest cluster center\n",
    "        sse.append(kmeans.inertia_)\n",
    "    plt.figure()\n",
    "    plt.plot(K,sse,'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Sum_of_squared_distances')\n",
    "    plt.title('Elbow Method For Optimal k')\n",
    "    plt.show()\n",
    "    return kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Elbow for full training data\n",
    "elbow_plot(query_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd266e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clustering dataframe \n",
    "def df_clustering(queries, embeddings, labels=None, clusters=2):\n",
    "    \"\"\"\n",
    "        parameters:\n",
    "        - queries: list of queries\n",
    "        - embeddings: list of embeddings corresponding to queries\n",
    "        - clusters: no. of clusters for kmeans\n",
    "    \"\"\"\n",
    "    num_clusters = clusters\n",
    "    clf = KMeans(n_clusters=num_clusters, \n",
    "                max_iter=100, \n",
    "                init='k-means++', \n",
    "                n_init=1)\n",
    "    clf.fit_predict(embeddings)\n",
    "    cluster_assignment = clf.labels_\n",
    "\n",
    "    cdf=pd.DataFrame(columns=[\"cluster_id\",\"sentence_id\",\"sentence\",'label'])\n",
    "\n",
    "    cdf['cluster_id']=clf.labels_\n",
    "    cdf['sentence_id']=[i for i in range(len(clf.labels_))]\n",
    "    cdf['sentence']=queries\n",
    "    cdf['label']=labels\n",
    "                                            \n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9775bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 4\n",
    "clf = KMeans(n_clusters=num_clusters, \n",
    "            max_iter=100, \n",
    "            init='k-means++', \n",
    "            n_init=1)\n",
    "clf.fit_predict(query_embeddings)\n",
    "cluster_assignment = clf.labels_\n",
    "\n",
    "cdf=pd.DataFrame(columns=[\"cluster_id\",\"sentence_id\",\"sentence\"])\n",
    "\n",
    "for i in range(len(cluster_assignment)):\n",
    "    new_row=pd.DataFrame({\"cluster_id\":[cluster_assignment[i]],\n",
    "                                \"sentence_id\":[i],\n",
    "                                \"sentence\":[queries[i]]\n",
    "                           })\n",
    "    cdf=pd.concat([cdf,new_row],axis=0,ignore_index=True)\n",
    "\n",
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254067b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PCA to reduce the dimension to project the result to 2-d scatter plot\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(query_embeddings)\n",
    "\n",
    "df_pca = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "df_pca['sentence']=queries\n",
    "# Combine PCA results with K-means results to see clustering\n",
    "df_k=df_pca.merge(cdf,right_on=['sentence'],left_on=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94adcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ls_clusters=pd.unique(df_k[\"cluster_id\"])\n",
    "ls_colors=['tab:blue', 'tab:orange', 'tab:green','tab:purple']\n",
    "#ls_colors=df_k[\"cluster_id\"].astype('category').cat.codes\n",
    "for id in range(len(ls_clusters)):\n",
    "    ax.scatter(df_k[df_k['cluster_id']==ls_clusters[id]]['principal component 1'],\n",
    "               df_k[df_k['cluster_id']==ls_clusters[id]]['principal component 2'], c=ls_colors[id], label=ls_clusters[id],\n",
    "               alpha=0.9, edgecolors='none')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b29b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
