{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import json\n",
    "import os\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import transformers\n",
    "from transformers import BertModel, BertTokenizer\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# specify GPU\n",
    "device = torch.device(\"cuda\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "class LoadingData():\n",
    "            \n",
    "    def __init__(self):\n",
    "        train_file_path = os.path.join(\"..\",\"input\",\"nlp-benchmarking-data-for-intent-and-entity\",\"benchmarking_data\",\"Train\")\n",
    "        validation_file_path = os.path.join(\"..\",\"input\",\"nlp-benchmarking-data-for-intent-and-entity\",\"benchmarking_data\",\"Validate\")\n",
    "        category_id = 0\n",
    "        self.cat_to_intent = {}\n",
    "        self.intent_to_cat = {}\n",
    "        \n",
    "        for dirname, _, filenames in os.walk(train_file_path):\n",
    "            for filename in filenames:\n",
    "                file_path = os.path.join(dirname, filename)\n",
    "                intent_id = filename.replace(\".json\",\"\")\n",
    "                self.cat_to_intent[category_id] = intent_id\n",
    "                self.intent_to_cat[intent_id] = category_id\n",
    "                category_id+=1\n",
    "        print(self.cat_to_intent)\n",
    "        print(self.intent_to_cat)\n",
    "        '''Training data'''\n",
    "        training_data = list() \n",
    "        for dirname, _, filenames in os.walk(train_file_path):\n",
    "            for filename in filenames:\n",
    "                file_path = os.path.join(dirname, filename)\n",
    "                intent_id = filename.replace(\".json\",\"\")\n",
    "                training_data+=self.make_data_for_intent_from_json(file_path,intent_id,self.intent_to_cat[intent_id])\n",
    "        self.train_data_frame = pd.DataFrame(training_data, columns =['query', 'intent','category'])   \n",
    "        \n",
    "        self.train_data_frame = self.train_data_frame.sample(frac = 1)\n",
    "\n",
    "\n",
    "        \n",
    "        '''Validation data'''\n",
    "        validation_data = list()    \n",
    "        for dirname, _, filenames in os.walk(validation_file_path):\n",
    "            for filename in filenames:\n",
    "                file_path = os.path.join(dirname, filename)\n",
    "                intent_id = filename.replace(\".json\",\"\")\n",
    "                validation_data +=self.make_data_for_intent_from_json(file_path,intent_id,self.intent_to_cat[intent_id])                \n",
    "        self.validation_data_frame = pd.DataFrame(validation_data, columns =['query', 'intent','category'])\n",
    "\n",
    "        self.validation_data_frame = self.validation_data_frame.sample(frac = 1)\n",
    "        \n",
    "        \n",
    "    def make_data_for_intent_from_json(self,json_file,intent_id,cat):\n",
    "        json_d = json.load(open(json_file))         \n",
    "        \n",
    "        json_dict = json_d[intent_id]\n",
    "\n",
    "        sent_list = list()\n",
    "        for i in json_dict:\n",
    "            each_list = i['data']\n",
    "            sent =\"\"\n",
    "            for i in each_list:\n",
    "                sent = sent + i['text']+ \" \"\n",
    "            sent =sent[:-1]\n",
    "            for i in range(3):\n",
    "                sent = sent.replace(\"  \",\" \")\n",
    "            sent_list.append((sent,intent_id,cat))\n",
    "        return sent_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "{}\n"
     ]
    }
   ],
   "source": [
    "ld = LoadingData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = ld.train_data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_map,id2label = ld.intent_to_cat,ld.cat_to_intent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_text, val_text, train_labels, val_labels = train_test_split(train_df['query'], train_df['category'], \n",
    "                                                                    random_state=2018, \n",
    "                                                                    test_size=0.2, \n",
    "                                                                    stratify=train_df['category'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7fe809e219e143b08f6036dfa899cb06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9f496749d156491cb235422e6a22ab4f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "902730deca3e4324a0c43d7fcbe556fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "bert = BertModel.from_pretrained(\"bert-base-uncased\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "seq_len = [len(i.split()) for i in train_text]\n",
    "\n",
    "pd.Series(seq_len).hist(bins = 30)\n",
    "max_seq_len = max(seq_len)\n",
    "print(max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize and encode sequences in the training set\n",
    "if max_seq_len>512:\n",
    "    max_seq_len = 512\n",
    "tokens_train = tokenizer.batch_encode_plus(\n",
    "    train_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# tokenize and encode sequences in the validation set\n",
    "tokens_val = tokenizer.batch_encode_plus(\n",
    "    val_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_y: tensor([2, 2, 5,  ..., 4, 1, 2])\n",
      "val_y: tensor([2, 5, 6,  ..., 6, 3, 2])\n"
     ]
    }
   ],
   "source": [
    "# for train set\n",
    "train_seq = torch.tensor(tokens_train['input_ids'])\n",
    "train_mask = torch.tensor(tokens_train['attention_mask'])\n",
    "train_y = torch.tensor(train_labels.tolist())\n",
    "print(\"train_y:\",train_y)\n",
    "# for validation set\n",
    "val_seq = torch.tensor(tokens_val['input_ids'])\n",
    "val_mask = torch.tensor(tokens_val['attention_mask'])\n",
    "val_y = torch.tensor(val_labels.tolist())\n",
    "print(\"val_y:\",val_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "#define a batch size\n",
    "batch_size = 16\n",
    "\n",
    "# wrap tensors\n",
    "train_data = TensorDataset(train_seq, train_mask, train_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "train_sampler = RandomSampler(train_data)\n",
    "\n",
    "# dataLoader for train set\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# wrap tensors\n",
    "val_data = TensorDataset(val_seq, val_mask, val_y)\n",
    "\n",
    "# sampler for sampling the data during training\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "\n",
    "# dataLoader for validation set\n",
    "val_dataloader = DataLoader(val_data, sampler = val_sampler, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freeze all the parameters\n",
    "for param in bert.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BERT_Arch(nn.Module):\n",
    "    def __init__(self, bert,label_map):\n",
    "        super(BERT_Arch, self).__init__()\n",
    "        self.bert = bert \n",
    "      \n",
    "        # dropout layer\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # relu activation function\n",
    "        self.relu =  nn.ReLU()\n",
    "\n",
    "        # dense layer 1\n",
    "        self.fc1 = nn.Linear(768,512)\n",
    "\n",
    "        # dense layer 2 (Output layer)\n",
    "        self.fc2 = nn.Linear(512,len(label_map))\n",
    "\n",
    "        #softmax activation function\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "        #define the forward pass\n",
    "    def forward(self, sent_id, mask):\n",
    "\n",
    "        #pass the inputs to the model  \n",
    "        _, cls_hs = self.bert(sent_id, attention_mask=mask)\n",
    "\n",
    "        x = self.fc1(cls_hs)\n",
    "\n",
    "        x = self.relu(x)\n",
    "\n",
    "        x = self.dropout(x)\n",
    "\n",
    "        # output layer\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        # apply softmax activation\n",
    "        x = self.softmax(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass the pre-trained BERT to our define architecture\n",
    "model = BERT_Arch(bert,label_map)\n",
    "\n",
    "# push the model to GPU\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer from hugging face transformers\n",
    "from transformers import AdamW\n",
    "\n",
    "# define the optimizer\n",
    "optimizer = AdamW(model.parameters(), lr = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.99827992 1.00528763 1.00657234 0.98455357 1.01369737 0.98455357\n",
      " 1.00786034]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "#compute the class weights\n",
    "class_wts = compute_class_weight('balanced', np.unique(train_labels), train_labels)\n",
    "\n",
    "print(class_wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert class weights to tensor\n",
    "weights= torch.tensor(class_wts,dtype=torch.float)\n",
    "weights = weights.to(device)\n",
    "\n",
    "# loss function\n",
    "cross_entropy  = nn.NLLLoss(weight=weights) \n",
    "\n",
    "# number of training epochs\n",
    "epochs = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to train the model\n",
    "def train():\n",
    "    model.train()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "  \n",
    "    # empty list to save model predictions\n",
    "    total_preds=[]\n",
    "    total_labels =[]\n",
    "  \n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(train_dataloader):\n",
    "    \n",
    "        # progress update after every 50 batches.\n",
    "        if step % 100 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(train_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [r.to(device) for r in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # clear previously calculated gradients \n",
    "        model.zero_grad()        \n",
    "\n",
    "        # get model predictions for the current batch\n",
    "        preds = model(sent_id, mask)\n",
    "\n",
    "        # compute the loss between actual and predicted values\n",
    "        loss = cross_entropy(preds, labels)\n",
    "\n",
    "        # add on to the total loss\n",
    "        total_loss = total_loss + loss.item()\n",
    "\n",
    "        # backward pass to calculate the gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # clip the the gradients to 1.0. It helps in preventing the exploding gradient problem\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "        # update parameters\n",
    "        optimizer.step()\n",
    "\n",
    "        # model predictions are stored on GPU. So, push it to CPU\n",
    "        preds = preds.detach().cpu().numpy()\n",
    "        preds = np.argmax(preds, axis=1)\n",
    "        # append the model predictions\n",
    "        total_preds+=list(preds)\n",
    "        total_labels+=labels.tolist()\n",
    "\n",
    "    # compute the training loss of the epoch\n",
    "    avg_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "    # predictions are in the form of (no. of batches, size of batch, no. of classes).\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    #total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    f1 = f1_score(total_labels, total_preds, average='weighted')\n",
    "    #returns the loss and predictions\n",
    "    return avg_loss, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for evaluating the model\n",
    "def evaluate():\n",
    "  \n",
    "    print(\"\\nEvaluating...\")\n",
    "\n",
    "    # deactivate dropout layers\n",
    "    model.eval()\n",
    "\n",
    "    total_loss, total_accuracy = 0, 0\n",
    "\n",
    "    # empty list to save the model predictions\n",
    "    total_preds = []\n",
    "    total_labels = []\n",
    "    # iterate over batches\n",
    "    for step,batch in enumerate(val_dataloader):\n",
    "    \n",
    "        # Progress update every 50 batches.\n",
    "        if step % 50 == 0 and not step == 0:\n",
    "\n",
    "          # Calculate elapsed time in minutes.\n",
    "          #elapsed = format_time(time.time() - t0)\n",
    "\n",
    "          # Report progress.\n",
    "          print('  Batch {:>5,}  of  {:>5,}.'.format(step, len(val_dataloader)))\n",
    "\n",
    "        # push the batch to gpu\n",
    "        batch = [t.to(device) for t in batch]\n",
    "\n",
    "        sent_id, mask, labels = batch\n",
    "\n",
    "        # deactivate autograd\n",
    "        with torch.no_grad():\n",
    "\n",
    "            # model predictions\n",
    "            preds = model(sent_id, mask)\n",
    "\n",
    "            # compute the validation loss between actual and predicted values\n",
    "            loss = cross_entropy(preds,labels)\n",
    "\n",
    "            total_loss = total_loss + loss.item()\n",
    "\n",
    "            preds = preds.detach().cpu().numpy()\n",
    "            preds = np.argmax(preds, axis=1)\n",
    "            total_preds+=list(preds)\n",
    "            total_labels+=labels.tolist()\n",
    "    # compute the validation loss of the epoch\n",
    "    avg_loss = total_loss / len(val_dataloader) \n",
    "\n",
    "    # reshape the predictions in form of (number of samples, no. of classes)\n",
    "    #total_preds  = np.concatenate(total_preds, axis=0)\n",
    "    \n",
    "    f1 = f1_score(total_labels, total_preds, average='weighted')\n",
    "    return avg_loss, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(filename, epoch, model, optimizer, label_map, id2label):\n",
    "    state = {\n",
    "        'epoch': epoch,\n",
    "        'model': model,\n",
    "        'optimizer': optimizer,\n",
    "        'label_map': label_map,\n",
    "        'id_map':id2label}\n",
    "    torch.save(state, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Epoch 1 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.391\n",
      "Validation Loss: 0.243\n",
      "\n",
      "Training F1: 0.864\n",
      "Validation F1: 0.916\n",
      "\n",
      " Epoch 2 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.375\n",
      "Validation Loss: 0.375\n",
      "\n",
      "Training F1: 0.865\n",
      "Validation F1: 0.857\n",
      "\n",
      " Epoch 3 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.360\n",
      "Validation Loss: 0.223\n",
      "\n",
      "Training F1: 0.872\n",
      "Validation F1: 0.925\n",
      "\n",
      " Epoch 4 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.340\n",
      "Validation Loss: 0.196\n",
      "\n",
      "Training F1: 0.881\n",
      "Validation F1: 0.931\n",
      "\n",
      " Epoch 5 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.328\n",
      "Validation Loss: 0.207\n",
      "\n",
      "Training F1: 0.888\n",
      "Validation F1: 0.926\n",
      "\n",
      " Epoch 6 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.341\n",
      "Validation Loss: 0.310\n",
      "\n",
      "Training F1: 0.882\n",
      "Validation F1: 0.889\n",
      "\n",
      " Epoch 7 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.308\n",
      "Validation Loss: 0.197\n",
      "\n",
      "Training F1: 0.894\n",
      "Validation F1: 0.932\n",
      "\n",
      " Epoch 8 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.309\n",
      "Validation Loss: 0.280\n",
      "\n",
      "Training F1: 0.891\n",
      "Validation F1: 0.911\n",
      "\n",
      " Epoch 9 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.306\n",
      "Validation Loss: 0.211\n",
      "\n",
      "Training F1: 0.896\n",
      "Validation F1: 0.919\n",
      "\n",
      " Epoch 10 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.294\n",
      "Validation Loss: 0.201\n",
      "\n",
      "Training F1: 0.896\n",
      "Validation F1: 0.929\n",
      "\n",
      " Epoch 11 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.294\n",
      "Validation Loss: 0.170\n",
      "\n",
      "Training F1: 0.897\n",
      "Validation F1: 0.942\n",
      "\n",
      " Epoch 12 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.296\n",
      "Validation Loss: 0.207\n",
      "\n",
      "Training F1: 0.898\n",
      "Validation F1: 0.927\n",
      "\n",
      " Epoch 13 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.283\n",
      "Validation Loss: 0.303\n",
      "\n",
      "Training F1: 0.901\n",
      "Validation F1: 0.893\n",
      "\n",
      " Epoch 14 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.289\n",
      "Validation Loss: 0.228\n",
      "\n",
      "Training F1: 0.899\n",
      "Validation F1: 0.922\n",
      "\n",
      " Epoch 15 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.281\n",
      "Validation Loss: 0.164\n",
      "\n",
      "Training F1: 0.902\n",
      "Validation F1: 0.943\n",
      "\n",
      " Epoch 16 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.269\n",
      "Validation Loss: 0.206\n",
      "\n",
      "Training F1: 0.907\n",
      "Validation F1: 0.931\n",
      "\n",
      " Epoch 17 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.283\n",
      "Validation Loss: 0.213\n",
      "\n",
      "Training F1: 0.903\n",
      "Validation F1: 0.926\n",
      "\n",
      " Epoch 18 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.267\n",
      "Validation Loss: 0.195\n",
      "\n",
      "Training F1: 0.909\n",
      "Validation F1: 0.931\n",
      "\n",
      " Epoch 19 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.261\n",
      "Validation Loss: 0.150\n",
      "\n",
      "Training F1: 0.909\n",
      "Validation F1: 0.951\n",
      "\n",
      " Epoch 20 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.252\n",
      "Validation Loss: 0.206\n",
      "\n",
      "Training F1: 0.914\n",
      "Validation F1: 0.933\n",
      "\n",
      " Epoch 21 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.266\n",
      "Validation Loss: 0.164\n",
      "\n",
      "Training F1: 0.909\n",
      "Validation F1: 0.948\n",
      "\n",
      " Epoch 22 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.267\n",
      "Validation Loss: 0.153\n",
      "\n",
      "Training F1: 0.909\n",
      "Validation F1: 0.945\n",
      "\n",
      " Epoch 23 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.246\n",
      "Validation Loss: 0.180\n",
      "\n",
      "Training F1: 0.916\n",
      "Validation F1: 0.941\n",
      "\n",
      " Epoch 24 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.261\n",
      "Validation Loss: 0.146\n",
      "\n",
      "Training F1: 0.910\n",
      "Validation F1: 0.952\n",
      "\n",
      " Epoch 25 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.260\n",
      "Validation Loss: 0.152\n",
      "\n",
      "Training F1: 0.908\n",
      "Validation F1: 0.948\n",
      "\n",
      " Epoch 26 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.257\n",
      "Validation Loss: 0.178\n",
      "\n",
      "Training F1: 0.908\n",
      "Validation F1: 0.939\n",
      "\n",
      " Epoch 27 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.245\n",
      "Validation Loss: 0.151\n",
      "\n",
      "Training F1: 0.914\n",
      "Validation F1: 0.952\n",
      "\n",
      " Epoch 28 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.246\n",
      "Validation Loss: 0.146\n",
      "\n",
      "Training F1: 0.915\n",
      "Validation F1: 0.952\n",
      "\n",
      " Epoch 29 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.240\n",
      "Validation Loss: 0.157\n",
      "\n",
      "Training F1: 0.917\n",
      "Validation F1: 0.949\n",
      "\n",
      " Epoch 30 / 30\n",
      "  Batch   100  of    690.\n",
      "  Batch   200  of    690.\n",
      "  Batch   300  of    690.\n",
      "  Batch   400  of    690.\n",
      "  Batch   500  of    690.\n",
      "  Batch   600  of    690.\n",
      "\n",
      "Evaluating...\n",
      "  Batch    50  of    173.\n",
      "  Batch   100  of    173.\n",
      "  Batch   150  of    173.\n",
      "\n",
      "Training Loss: 0.242\n",
      "Validation Loss: 0.162\n",
      "\n",
      "Training F1: 0.918\n",
      "Validation F1: 0.946\n"
     ]
    }
   ],
   "source": [
    "# set initial loss to infinite\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "# empty lists to store training and validation loss of each epoch\n",
    "train_losses=[]\n",
    "valid_losses=[]\n",
    "\n",
    "#for each epoch\n",
    "for epoch in range(epochs):\n",
    "     \n",
    "    print('\\n Epoch {:} / {:}'.format(epoch + 1, epochs))\n",
    "    \n",
    "    #train model\n",
    "    train_loss, f1_train = train()\n",
    "    \n",
    "    #evaluate model\n",
    "    valid_loss, f1_valid = evaluate()\n",
    "    \n",
    "    #save the best model\n",
    "    if valid_loss < best_valid_loss:\n",
    "        best_valid_loss = valid_loss\n",
    "        file_name = 'topic_saved_weights.pt'\n",
    "        save_checkpoint(file_name, epoch, model, optimizer, label_map, id2label)\n",
    "    \n",
    "    # append training and validation loss\n",
    "    train_losses.append(train_loss)\n",
    "    valid_losses.append(valid_loss)\n",
    "    \n",
    "    print(f'\\nTraining Loss: {train_loss:.3f}')\n",
    "    print(f'Validation Loss: {valid_loss:.3f}')\n",
    "    print(f'\\nTraining F1: {f1_train:.3f}')\n",
    "    print(f'Validation F1: {f1_valid:.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'topic_saved_weights.pt'\n",
    "test_df = ld.validation_data_frame\n",
    "\n",
    "checkpoint = torch.load(path,map_location=device)\n",
    "model = checkpoint.get(\"model\")\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "\n",
    "# tokenize and encode sequences in the test set\n",
    "test_text,test_labels = test_df[\"query\"],test_df[\"category\"]\n",
    "\n",
    "tokens_test = tokenizer.batch_encode_plus(\n",
    "    test_text.tolist(),\n",
    "    max_length = max_seq_len,\n",
    "    pad_to_max_length=True,\n",
    "    truncation=True,\n",
    "    return_token_type_ids=False\n",
    ")\n",
    "\n",
    "# for test set\n",
    "test_seq = torch.tensor(tokens_test['input_ids'])\n",
    "test_mask = torch.tensor(tokens_test['attention_mask'])\n",
    "test_y = torch.tensor(test_labels.tolist())\n",
    "print(\"test_y:\",test_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get predictions for test data\n",
    "with torch.no_grad():\n",
    "    preds = model(test_seq.to(device), test_mask.to(device))\n",
    "    preds = preds.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.argmax(preds, axis = 1)\n",
    "print(classification_report(test_y, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prediction:\n",
    "    def __init__(self):\n",
    "        path = 'topic_saved_weights.pt'\n",
    "\n",
    "        checkpoint = torch.load(path,map_location=device)\n",
    "        self.predictor = checkpoint.get(\"model\")\n",
    "        self.tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "        self.tag = checkpoint.get(\"id_map\")\n",
    "\n",
    "    def predict(self,text):\n",
    "        tokens = self.tokenizer.tokenize(text)\n",
    "        tokens = tokens[:max_seq_len - 2]\n",
    "        tokens = ['[CLS]'] + tokens + ['[SEP]']\n",
    "\n",
    "        input_ids = self.tokenizer.convert_tokens_to_ids(tokens)\n",
    "        input_ids = input_ids + [0] * (max_seq_len-len(input_ids))\n",
    "        input_ids = torch.tensor(input_ids).unsqueeze(0)\n",
    "        input_ids = input_ids.to(device)\n",
    "\n",
    "        input_mask = [1]*len(tokens) + [0] * (max_seq_len - len(tokens))\n",
    "        input_mask = torch.tensor(input_mask).unsqueeze(0)\n",
    "        input_mask = input_mask.to(device)\n",
    "\n",
    "        logits = self.predictor(input_ids,input_mask)\n",
    "        prob = torch.nn.functional.softmax(logits,dim=1)\n",
    "        result = [(self.tag[idx],item *100) for idx,item in enumerate(prob[0].tolist())]\n",
    "        preds = logits.detach().cpu().numpy()\n",
    "        pred_val = np.argmax(preds)\n",
    "        pred_val = self.tag[pred_val]\n",
    "        return result,pred_val\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = Prediction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PlayMusic\n",
      "[('BookRestaurant', 1.2048614905779687e-05), ('SearchScreeningEvent', 0.06772816996090114), ('RateBook', 7.69690757351782e-05), ('GetWeather', 7.716318251027587e-07), ('AddToPlaylist', 41.87126159667969), ('PlayMusic', 56.4595103263855), ('SearchCreativeWork', 1.6014140099287033)]\n",
      "RateBook\n",
      "[('BookRestaurant', 1.0315424070483914e-06), ('SearchScreeningEvent', 2.932396769850243e-07), ('RateBook', 100.0), ('GetWeather', 8.08519862172119e-08), ('AddToPlaylist', 3.296656814200105e-06), ('PlayMusic', 1.5063672531567818e-08), ('SearchCreativeWork', 1.3556576305973067e-06)]\n"
     ]
    }
   ],
   "source": [
    "list_input = [\"Play music from my relentless playlist\",\n",
    "             \"I rate this essay a four of 6\"]\n",
    "\n",
    "for item in list_input:\n",
    "    confidence,pred_val = pred.predict(item)\n",
    "    print(pred_val)\n",
    "    print(confidence)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
