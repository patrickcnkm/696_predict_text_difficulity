{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fine-tuning RoBERTa by Huggingface for Fake News classification. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = './01_data'\n",
    "output_path = './tmp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "import torch\n",
    "#from torchtext.data import Field, TabularDataset, BucketIterator, Iterator\n",
    "\n",
    "from transformers import RobertaTokenizer, RobertaModel, AdamW, get_linear_schedule_with_warmup\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.getLogger(\"transformers.tokenization_utils_base\").setLevel(logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load CSV file with dataset. Perform basic transformations.\n",
    "train_data = pd.read_csv(f\"{data_path}/WikiLarge_Train.csv\")\n",
    "#df = df.drop(['Unnamed: 0'], axis=1)\n",
    "\n",
    "#encode_label = {'FAKE' : 0, 'REAL' : 1}\n",
    "\n",
    "# Discard items with less than 5 words in text.\n",
    "#df = df[df.text.str.len() >= 5]\n",
    "\n",
    "#df['label'] = df['label'].map(encode_label)\n",
    "#df['titletext'] = df['title'] + \". \" + df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot histogram with the length. Truncate max length to 5000 tokens.\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "train_data['length'] = train_data['original_text'].apply(lambda x: len(x.split()))\n",
    "sns.distplot(train_data[train_data['length'] < 5000]['length'])\n",
    "plt.title('Frequence of documents of a given length', fontsize=14)\n",
    "plt.xlabel('length', fontsize=14)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save preprocessed data, cropped to max length of the model.\n",
    "train_data['original_text'] = train_data['original_text'].apply(lambda x: \" \".join(x.split()[:512]))\n",
    "#df.to_csv(f\"{data_path}/prep_news.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "# Set random seed and set device to GPU.\n",
    "torch.manual_seed(17)\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda:0')\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize tokenizer.\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "size=round(len(train_data)*1)\n",
    "r_train=train_data.sample(n=size,random_state=1)\n",
    "texts=list(r_train[\"original_text\"])\n",
    "labels=list(r_train[\"label\"])\n",
    "    \n",
    "rest_texts, test_texts, rest_labels, test_labels = train_test_split(texts, labels, test_size=0.1, random_state=1)\n",
    "train_texts, dev_texts, train_labels, dev_labels = train_test_split(rest_texts, rest_labels, test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1}\n"
     ]
    }
   ],
   "source": [
    "target_names = list(set(labels))\n",
    "label2idx = {label: idx for idx, label in enumerate(target_names)}\n",
    "print(label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "MAX_SEQ_LENGTH=80\n",
    "\n",
    "class BertInputItem(object):\n",
    "    \"\"\"An item with all the necessary attributes for finetuning BERT.\"\"\"\n",
    "\n",
    "    def __init__(self, text, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.text = text\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        \n",
    "\n",
    "def convert_examples_to_inputs(example_texts, example_labels, label2idx, max_seq_length, tokenizer):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    \n",
    "    input_items = []\n",
    "    examples = zip(example_texts, example_labels)\n",
    "    for (ex_index, (text, label)) in enumerate(examples):\n",
    "\n",
    "        # Create a list of token ids\n",
    "        input_ids = tokenizer.encode(f\"[CLS] {text} [SEP]\")\n",
    "        if len(input_ids) > max_seq_length:\n",
    "            input_ids = input_ids[:max_seq_length]\n",
    "\n",
    "        # All our tokens are in the first input segment (id 0).\n",
    "        segment_ids = [0] * len(input_ids)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        label_id = label2idx[label]\n",
    "\n",
    "        input_items.append(\n",
    "            BertInputItem(text=text,\n",
    "                          input_ids=input_ids,\n",
    "                          input_mask=input_mask,\n",
    "                          segment_ids=segment_ids,\n",
    "                          label_id=label_id))\n",
    "\n",
    "        \n",
    "    return input_items\n",
    "\n",
    "train_features = convert_examples_to_inputs(train_texts, train_labels, label2idx, MAX_SEQ_LENGTH, tokenizer)\n",
    "dev_features = convert_examples_to_inputs(dev_texts, dev_labels, label2idx, MAX_SEQ_LENGTH, tokenizer)\n",
    "test_features = convert_examples_to_inputs(test_texts, test_labels, label2idx, MAX_SEQ_LENGTH, tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "\n",
    "def get_data_loader(features, max_seq_length, batch_size, shuffle=True): \n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "\n",
    "    #dataloader = DataLoader(data, shuffle=shuffle, batch_size=batch_size)\n",
    "    # dataloader tuning in https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html\n",
    "   \n",
    "    dataloader = DataLoader(data, shuffle=shuffle, batch_size=batch_size,num_workers=2,pin_memory=True)\n",
    "    return dataloader\n",
    "\n",
    "#BATCH_SIZE = 16\n",
    "# Tuning in https://mccormickml.com/2019/07/22/BERT-fine-tuning/#41-bertforsequenceclassification\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "train_dataloader = get_data_loader(train_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=True)\n",
    "dev_dataloader = get_data_loader(dev_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=False)\n",
    "test_dataloader = get_data_loader(test_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set tokenizer hyperparameters.\n",
    "MAX_SEQ_LEN = 256\n",
    "BATCH_SIZE = 16\n",
    "PAD_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.pad_token)\n",
    "UNK_INDEX = tokenizer.convert_tokens_to_ids(tokenizer.unk_token)\n",
    "\n",
    "\n",
    "# Define columns to read.\n",
    "label_field = Field(sequential=False, use_vocab=False, batch_first=True)\n",
    "text_field = Field(use_vocab=False, \n",
    "                   tokenize=tokenizer.encode, \n",
    "                   include_lengths=False, \n",
    "                   batch_first=True,\n",
    "                   fix_length=MAX_SEQ_LEN, \n",
    "                   pad_token=PAD_INDEX, \n",
    "                   unk_token=UNK_INDEX)\n",
    "\n",
    "fields = {'titletext' : ('titletext', text_field), 'label' : ('label', label_field)}\n",
    "\n",
    "\n",
    "# Read preprocessed CSV into TabularDataset and split it into train, test and valid.\n",
    "train_data, valid_data, test_data = TabularDataset(path=f\"{data_path}/prep_news.csv\", \n",
    "                                                   format='CSV', \n",
    "                                                   fields=fields, \n",
    "                                                   skip_header=False).split(split_ratio=[0.70, 0.2, 0.1], \n",
    "                                                                            stratified=True, \n",
    "                                                                            strata_field='label')\n",
    "\n",
    "# Create train and validation iterators.\n",
    "train_iter, valid_iter = BucketIterator.splits((train_data, valid_data),\n",
    "                                               batch_size=BATCH_SIZE,\n",
    "                                               device=device,\n",
    "                                               shuffle=True,\n",
    "                                               sort_key=lambda x: len(x.titletext), \n",
    "                                               sort=True, \n",
    "                                               sort_within_batch=False)\n",
    "\n",
    "# Test iterator, no shuffling or sorting required.\n",
    "test_iter = Iterator(test_data, batch_size=BATCH_SIZE, device=device, train=False, shuffle=False, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions for saving and loading model parameters and metrics.\n",
    "def save_checkpoint(path, model, valid_loss):\n",
    "    torch.save({'model_state_dict': model.state_dict(),\n",
    "                  'valid_loss': valid_loss}, path)\n",
    "\n",
    "    \n",
    "def load_checkpoint(path, model):    \n",
    "    state_dict = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(state_dict['model_state_dict'])\n",
    "    \n",
    "    return state_dict['valid_loss']\n",
    "\n",
    "\n",
    "def save_metrics(path, train_loss_list, valid_loss_list, global_steps_list):   \n",
    "    state_dict = {'train_loss_list': train_loss_list,\n",
    "                  'valid_loss_list': valid_loss_list,\n",
    "                  'global_steps_list': global_steps_list}\n",
    "    \n",
    "    torch.save(state_dict, path)\n",
    "\n",
    "\n",
    "def load_metrics(path):    \n",
    "    state_dict = torch.load(path, map_location=device)\n",
    "    return state_dict['train_loss_list'], state_dict['valid_loss_list'], state_dict['global_steps_list']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model with extra layers on top of RoBERTa\n",
    "class ROBERTAClassifier(torch.nn.Module):\n",
    "    def __init__(self, dropout_rate=0.3):\n",
    "        super(ROBERTAClassifier, self).__init__()\n",
    "        \n",
    "        self.roberta = RobertaModel.from_pretrained('roberta-base')\n",
    "        self.d1 = torch.nn.Dropout(dropout_rate)\n",
    "        self.l1 = torch.nn.Linear(768, 64)\n",
    "        self.bn1 = torch.nn.LayerNorm(64)\n",
    "        self.d2 = torch.nn.Dropout(dropout_rate)\n",
    "        self.l2 = torch.nn.Linear(64, 2)\n",
    "        \n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        _, x = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        x = self.d1(x)\n",
    "        x = self.l1(x)\n",
    "        x = self.bn1(x)\n",
    "        x = torch.nn.Tanh()(x)\n",
    "        x = self.d2(x)\n",
    "        x = self.l2(x)\n",
    "        \n",
    "        return x  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pretrain(model, \n",
    "             optimizer, \n",
    "             train_iter, \n",
    "             valid_iter, \n",
    "             scheduler = None,\n",
    "             valid_period = len(train_dataloader),\n",
    "             num_epochs = 5):\n",
    "    \n",
    "    # Pretrain linear layers, do not train bert\n",
    "    for param in model.roberta.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    # Initialize losses and loss histories\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0   \n",
    "    global_step = 0  \n",
    "    \n",
    "    # Train loop\n",
    "    for epoch in range(num_epochs):\n",
    "        for (source, target), _ in train_iter:\n",
    "            mask = (source != PAD_INDEX).type(torch.uint8)\n",
    "            \n",
    "            y_pred = model(input_ids=source,  \n",
    "                           attention_mask=mask)\n",
    "            \n",
    "            loss = torch.nn.CrossEntropyLoss()(y_pred, target)\n",
    "   \n",
    "            loss.backward()\n",
    "            \n",
    "            # Optimizer and scheduler step\n",
    "            optimizer.step()    \n",
    "            scheduler.step()\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Update train loss and global step\n",
    "            train_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # Validation loop. Save progress and evaluate model performance.\n",
    "            if global_step % valid_period == 0:\n",
    "                model.eval()\n",
    "                \n",
    "                with torch.no_grad():                    \n",
    "                    for (source, target), _ in valid_iter:\n",
    "                        mask = (source != PAD_INDEX).type(torch.uint8)\n",
    "                        \n",
    "                        y_pred = model(input_ids=source, \n",
    "                                       attention_mask=mask)\n",
    "                        \n",
    "                        loss = torch.nn.CrossEntropyLoss()(y_pred, target)\n",
    "                        \n",
    "                        valid_loss += loss.item()\n",
    "\n",
    "                # Store train and validation loss history\n",
    "                train_loss = train_loss / valid_period\n",
    "                valid_loss = valid_loss / len(valid_iter)\n",
    "                \n",
    "                model.train()\n",
    "\n",
    "                # print summary\n",
    "                print('Epoch [{}/{}], global step [{}/{}], PT Loss: {:.4f}, Val Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_iter),\n",
    "                              train_loss, valid_loss))\n",
    "                \n",
    "                train_loss = 0.0                \n",
    "                valid_loss = 0.0\n",
    "    \n",
    "    # Set bert parameters back to trainable\n",
    "    for param in model.roberta.parameters():\n",
    "        param.requires_grad = True\n",
    "        \n",
    "    print('Pre-training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Function\n",
    "\n",
    "def train(model,\n",
    "          optimizer,\n",
    "          train_iter,\n",
    "          valid_iter,\n",
    "          scheduler = None,\n",
    "          num_epochs = 5,\n",
    "          valid_period = len(train_dataloader),\n",
    "          output_path = output_path):\n",
    "    \n",
    "    # Initialize losses and loss histories\n",
    "    train_loss = 0.0\n",
    "    valid_loss = 0.0\n",
    "    train_loss_list = []\n",
    "    valid_loss_list = []\n",
    "    best_valid_loss = float('Inf')\n",
    "    \n",
    "    global_step = 0\n",
    "    global_steps_list = []\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    # Train loop\n",
    "    for epoch in range(num_epochs):\n",
    "        for (source, target), _ in train_iter:\n",
    "            mask = (source != PAD_INDEX).type(torch.uint8)\n",
    "\n",
    "            y_pred = model(input_ids=source,  \n",
    "                           attention_mask=mask)\n",
    "            #output = model(input_ids=source,\n",
    "            #              labels=target,\n",
    "            #              attention_mask=mask)\n",
    "            \n",
    "            loss = torch.nn.CrossEntropyLoss()(y_pred, target)\n",
    "            #loss = output[0]\n",
    "            \n",
    "            loss.backward()\n",
    "            \n",
    "            #torch.nn.utils.clip_grad_norm_(model.parameters(), 0.1)\n",
    "            \n",
    "            # Optimizer and scheduler step\n",
    "            optimizer.step()    \n",
    "            scheduler.step()\n",
    "                \n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Update train loss and global step\n",
    "            train_loss += loss.item()\n",
    "            global_step += 1\n",
    "\n",
    "            # Validation loop. Save progress and evaluate model performance.\n",
    "            if global_step % valid_period == 0:\n",
    "                model.eval()\n",
    "                \n",
    "                with torch.no_grad():                    \n",
    "                    for (source, target), _ in valid_iter:\n",
    "                        mask = (source != PAD_INDEX).type(torch.uint8)\n",
    "\n",
    "                        y_pred = model(input_ids=source, \n",
    "                                       attention_mask=mask)\n",
    "                        #output = model(input_ids=source,\n",
    "                        #               labels=target,\n",
    "                        #               attention_mask=mask)\n",
    "                        \n",
    "                        loss = torch.nn.CrossEntropyLoss()(y_pred, target)\n",
    "                        #loss = output[0]\n",
    "                        \n",
    "                        valid_loss += loss.item()\n",
    "\n",
    "                # Store train and validation loss history\n",
    "                train_loss = train_loss / valid_period\n",
    "                valid_loss = valid_loss / len(valid_iter)\n",
    "                train_loss_list.append(train_loss)\n",
    "                valid_loss_list.append(valid_loss)\n",
    "                global_steps_list.append(global_step)\n",
    "\n",
    "                # print summary\n",
    "                print('Epoch [{}/{}], global step [{}/{}], Train Loss: {:.4f}, Valid Loss: {:.4f}'\n",
    "                      .format(epoch+1, num_epochs, global_step, num_epochs*len(train_iter),\n",
    "                              train_loss, valid_loss))\n",
    "                \n",
    "                # checkpoint\n",
    "                if best_valid_loss > valid_loss:\n",
    "                    best_valid_loss = valid_loss\n",
    "                    save_checkpoint(output_path + '/model.pkl', model, best_valid_loss)\n",
    "                    save_metrics(output_path + '/metric.pkl', train_loss_list, valid_loss_list, global_steps_list)\n",
    "                        \n",
    "                train_loss = 0.0                \n",
    "                valid_loss = 0.0\n",
    "                model.train()\n",
    "    \n",
    "    save_metrics(output_path + '/metric.pkl', train_loss_list, valid_loss_list, global_steps_list)\n",
    "    print('Training done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46e3f50cd7b94a0aa0f0944ec787c48b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/501M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================= Start pretraining ==============================\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "DataLoader worker (pid(s) 29716, 26192) exited unexpectedly",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mEmpty\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1162\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1163\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1164\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2032.0_x64__qbz5n2kfra8p0\\lib\\queue.py\u001b[0m in \u001b[0;36mget\u001b[1;34m(self, block, timeout)\u001b[0m\n\u001b[0;32m    178\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mremaining\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 179\u001b[1;33m                         \u001b[1;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    180\u001b[0m                     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnot_empty\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mremaining\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mEmpty\u001b[0m: ",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26144\\1241160110.py\u001b[0m in \u001b[0;36m<cell line: 16>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"======================= Start pretraining ==============================\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m pretrain(model=model,\n\u001b[0m\u001b[0;32m     17\u001b[0m          \u001b[0mtrain_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m          \u001b[0mvalid_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdev_dataloader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_26144\\3726533513.py\u001b[0m in \u001b[0;36mpretrain\u001b[1;34m(model, optimizer, train_iter, valid_iter, scheduler, valid_period, num_epochs)\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Train loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtrain_iter\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     23\u001b[0m             \u001b[0mmask\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0msource\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mPAD_INDEX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    679\u001b[0m                 \u001b[1;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    680\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 681\u001b[1;33m             \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    682\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    683\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[1;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1357\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1358\u001b[0m             \u001b[1;32massert\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1359\u001b[1;33m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1360\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[1;33m-=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1361\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1314\u001b[0m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_pin_memory_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_alive\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m                 \u001b[0msuccess\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1316\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m                     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\torch\\utils\\data\\dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m   1174\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1175\u001b[0m                 \u001b[0mpids_str\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m', '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpid\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfailed_workers\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'DataLoader worker (pid(s) {}) exited unexpectedly'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpids_str\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1177\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mqueue\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mEmpty\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: DataLoader worker (pid(s) 29716, 26192) exited unexpectedly"
     ]
    }
   ],
   "source": [
    "# Main training loop\n",
    "NUM_EPOCHS = 6\n",
    "steps_per_epoch = len(train_dataloader)\n",
    "\n",
    "model = ROBERTAClassifier(0.4)\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=1e-4)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=steps_per_epoch*1, \n",
    "                                            num_training_steps=steps_per_epoch*NUM_EPOCHS)\n",
    "\n",
    "print(\"======================= Start pretraining ==============================\")\n",
    "\n",
    "pretrain(model=model,\n",
    "         train_iter=train_dataloader,\n",
    "         valid_iter=dev_dataloader,\n",
    "         optimizer=optimizer,\n",
    "         scheduler=scheduler,\n",
    "         num_epochs=NUM_EPOCHS)\n",
    "\n",
    "NUM_EPOCHS = 12\n",
    "print(\"======================= Start training =================================\")\n",
    "optimizer = AdamW(model.parameters(), lr=2e-6)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps=steps_per_epoch*2, \n",
    "                                            num_training_steps=steps_per_epoch*NUM_EPOCHS)\n",
    "\n",
    "train(model=model, \n",
    "      train_iter=train_dataloader, \n",
    "      valid_iter=dev_dataloader, \n",
    "      optimizer=optimizer, \n",
    "      scheduler=scheduler, \n",
    "      num_epochs=NUM_EPOCHS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 8))\n",
    "train_loss_list, valid_loss_list, global_steps_list = load_metrics(output_path + '/metric.pkl')\n",
    "plt.plot(global_steps_list, train_loss_list, label='Train')\n",
    "plt.plot(global_steps_list, valid_loss_list, label='Valid')\n",
    "plt.xlabel('Global Steps', fontsize=14)\n",
    "plt.ylabel('Loss', fontsize=14)\n",
    "plt.legend(fontsize=14)\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation Function\n",
    "\n",
    "def evaluate(model, test_loader):\n",
    "    y_pred = []\n",
    "    y_true = []\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for (source, target), _ in test_loader:\n",
    "                mask = (source != PAD_INDEX).type(torch.uint8)\n",
    "                \n",
    "                output = model(source, attention_mask=mask)\n",
    "\n",
    "                y_pred.extend(torch.argmax(output, axis=-1).tolist())\n",
    "                y_true.extend(target.tolist())\n",
    "    \n",
    "    print('Classification Report:')\n",
    "    print(classification_report(y_true, y_pred, labels=[1,0], digits=4))\n",
    "    \n",
    "    cm = confusion_matrix(y_true, y_pred, labels=[1,0])\n",
    "    ax = plt.subplot()\n",
    "\n",
    "    sns.heatmap(cm, annot=True, ax = ax, cmap='Blues', fmt=\"d\")\n",
    "\n",
    "    ax.set_title('Confusion Matrix')\n",
    "\n",
    "    ax.set_xlabel('Predicted Labels')\n",
    "    ax.set_ylabel('True Labels')\n",
    "\n",
    "    ax.xaxis.set_ticklabels(['FAKE', 'REAL'])\n",
    "    ax.yaxis.set_ticklabels(['FAKE', 'REAL'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ROBERTAClassifier()\n",
    "model = model.to(device)\n",
    "\n",
    "load_checkpoint(output_path + '/model.pkl', model)\n",
    "\n",
    "evaluate(model, test_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(train_data))\n",
    "print(len(valid_data))\n",
    "print(len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
