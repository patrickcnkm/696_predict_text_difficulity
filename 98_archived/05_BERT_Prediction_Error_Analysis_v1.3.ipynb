{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3c1e9a",
   "metadata": {},
   "source": [
    "# BERT Prediction Error Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb64fc66",
   "metadata": {},
   "source": [
    "As the result of text classification by 3 types of BERT models ( BERT_BASED_UNCASED, BERT_LARGE_UNCASED, DISTILBERT), it is found that:\n",
    " - The smaller the model is, the higher the accuracies. Distilbert achieved 77.8% in contrast that Bert_large_uncased only achieved 70& around.\n",
    "\n",
    "In order to improve the accuracy level, we will perform the further study on those records whose prediction result are wrong, and see whether there are some ways.\n",
    "\n",
    "Given Bert_large_uncased does not achieved high accuracy, in order to save the potential efforts, we take the remaining 2 models for the error analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb7d23c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Disable 3 types of warning\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)\n",
    "warnings.filterwarnings(\"ignore\",category=(FutureWarning))\n",
    "warnings.filterwarnings(\"ignore\",category=(RuntimeWarning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aebc74e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "#Enable GPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6649879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "RANDOM_STATE=1\n",
    "#################### split data into train,dev,test##################\n",
    "def train_dev_test(dataset,random_state=RANDOM_STATE):\n",
    "    texts=list(dataset[\"original_text\"])\n",
    "    labels=list(dataset[\"label\"])\n",
    "    \n",
    "    target_names = list(set(labels))\n",
    "    label2idx = {label: idx for idx, label in enumerate(target_names)}\n",
    "    print(label2idx)\n",
    "\n",
    "    rest_texts, test_texts, rest_labels, test_labels = train_test_split(texts, labels, test_size=0.1, random_state=1)\n",
    "    train_texts, dev_texts, train_labels, dev_labels = train_test_split(rest_texts, rest_labels, test_size=0.1, random_state=1)\n",
    "\n",
    "    print(\"Train size:\", len(train_texts))\n",
    "    print(\"Dev size:\", len(dev_texts))\n",
    "    print(\"Test size:\", len(test_texts))\n",
    "    return (train_texts,dev_texts,test_texts),(train_labels,dev_labels,test_labels),(target_names,label2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3133966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(format = '%(asctime)s - %(levelname)s - %(name)s -   %(message)s',\n",
    "                    datefmt = '%m/%d/%Y %H:%M:%S',\n",
    "                    level = logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80206732",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "#################### Both class and the following function are used to prepare for input items##################\n",
    "\n",
    "class BertInputItem(object):\n",
    "    \"\"\"An item with all the necessary attributes for finetuning BERT.\"\"\"\n",
    "\n",
    "    def __init__(self, text, input_ids, input_mask, segment_ids, label_id):\n",
    "        self.text = text\n",
    "        self.input_ids = input_ids\n",
    "        self.input_mask = input_mask\n",
    "        self.segment_ids = segment_ids\n",
    "        self.label_id = label_id\n",
    "        \n",
    "\n",
    "def convert_examples_to_inputs(example_texts, example_labels, label2idx, max_seq_length, tokenizer):\n",
    "    \"\"\"Loads a data file into a list of `InputBatch`s.\"\"\"\n",
    "    \n",
    "    input_items = []\n",
    "    examples = zip(example_texts, example_labels)\n",
    "    for (ex_index, (text, label)) in enumerate(examples):\n",
    "\n",
    "        # Create a list of token ids\n",
    "        input_ids = tokenizer.encode(f\"[CLS] {text} [SEP]\")\n",
    "        if len(input_ids) > max_seq_length:\n",
    "            input_ids = input_ids[:max_seq_length]\n",
    "\n",
    "        # All our tokens are in the first input segment (id 0).\n",
    "        segment_ids = [0] * len(input_ids)\n",
    "\n",
    "        # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
    "        # tokens are attended to.\n",
    "        input_mask = [1] * len(input_ids)\n",
    "\n",
    "        # Zero-pad up to the sequence length.\n",
    "        padding = [0] * (max_seq_length - len(input_ids))\n",
    "        input_ids += padding\n",
    "        input_mask += padding\n",
    "        segment_ids += padding\n",
    "\n",
    "        assert len(input_ids) == max_seq_length\n",
    "        assert len(input_mask) == max_seq_length\n",
    "        assert len(segment_ids) == max_seq_length\n",
    "\n",
    "        label_id = label2idx[label]\n",
    "\n",
    "        input_items.append(\n",
    "            BertInputItem(text=text,\n",
    "                          input_ids=input_ids,\n",
    "                          input_mask=input_mask,\n",
    "                          segment_ids=segment_ids,\n",
    "                          label_id=label_id))\n",
    "\n",
    "        \n",
    "    return input_items\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb7b4d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, SequentialSampler\n",
    "\n",
    "#################### convert data for model input ##################\n",
    "\n",
    "def get_data_loader(features, max_seq_length, batch_size, shuffle=True): \n",
    "\n",
    "    all_input_ids = torch.tensor([f.input_ids for f in features], dtype=torch.long)\n",
    "    all_input_mask = torch.tensor([f.input_mask for f in features], dtype=torch.long)\n",
    "    all_segment_ids = torch.tensor([f.segment_ids for f in features], dtype=torch.long)\n",
    "    all_label_ids = torch.tensor([f.label_id for f in features], dtype=torch.long)\n",
    "    data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
    "\n",
    "    #dataloader = DataLoader(data, shuffle=shuffle, batch_size=batch_size)\n",
    "    # dataloader tuning in https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html\n",
    "   \n",
    "    dataloader = DataLoader(data, shuffle=shuffle, batch_size=batch_size,num_workers=2,pin_memory=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6fc1df8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "def evaluate(model, dataloader):\n",
    "    model.eval()\n",
    "    \n",
    "    eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    predicted_labels, correct_labels = [], []\n",
    "\n",
    "    for step, batch in enumerate(tqdm(dataloader, desc=\"Evaluation iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "\n",
    "        with torch.no_grad():\n",
    "            #tmp_eval_loss, logits = model(input_ids, attention_mask=input_mask,\n",
    "            #                              token_type_ids=segment_ids, labels=label_ids)[:2]\n",
    "            tmp_eval_loss, logits = model(input_ids, attention_mask=input_mask,\n",
    "                                         labels=label_ids)[:2]  # for distilbert\n",
    "        outputs = np.argmax(logits.to('cpu'), axis=1)\n",
    "        label_ids = label_ids.to('cpu').numpy()\n",
    "        \n",
    "        predicted_labels += list(outputs)\n",
    "        correct_labels += list(label_ids)\n",
    "        \n",
    "        eval_loss += tmp_eval_loss.mean().item()\n",
    "        nb_eval_steps += 1\n",
    "\n",
    "    eval_loss = eval_loss / nb_eval_steps\n",
    "    \n",
    "    correct_labels = np.array(correct_labels)\n",
    "    predicted_labels = np.array(predicted_labels)\n",
    "        \n",
    "    return eval_loss, correct_labels, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b598c5fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import trange\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "from transformers import AdamW,get_linear_schedule_with_warmup\n",
    "\n",
    "\n",
    "def train(model_name,train_texts,train_labels,dev_texts,dev_labels,target_names,label2idx,params):\n",
    "    \n",
    "    \n",
    "    ## Initialize bert model   \n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_name,target_names=target_names)\n",
    "    # Using trained model\n",
    "    model=DistilBertForSequenceClassification.from_pretrained(model_name,num_labels = len(target_names),\n",
    "                                                             output_attentions = False,\n",
    "                                                             output_hidden_states = False)  \n",
    "    \n",
    "    ## Prepare for data loading and parameter setting for bert model\n",
    "    train_features = convert_examples_to_inputs(train_texts,train_labels, label2idx, params['MAX_SEQ_LENGTH'], tokenizer)\n",
    "    train_dataloader = get_data_loader(train_features, params['MAX_SEQ_LENGTH'], params['BATCH_SIZE'], shuffle=True)\n",
    "    dev_features = convert_examples_to_inputs(dev_texts,dev_labels, label2idx, params['MAX_SEQ_LENGTH'], tokenizer)\n",
    "    dev_dataloader = get_data_loader(dev_features, params['MAX_SEQ_LENGTH'], params['BATCH_SIZE'], shuffle=True)\n",
    "\n",
    "    num_train_steps = int(len(train_dataloader.dataset) / params['BATCH_SIZE'] /params['GRADIENT_ACCUMULATION_STEPS'] * params['NUM_TRAIN_EPOCHS'])\n",
    "    num_warmup_steps = params['NUM_WARMUP_STEPS']\n",
    "\n",
    "    param_optimizer = list(model.named_parameters())\n",
    "    no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "    optimizer_grouped_parameters = [\n",
    "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "        ]\n",
    "\n",
    "    optimizer = AdamW(optimizer_grouped_parameters, lr=params['LEARNING_RATE'], correct_bias=False)\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps,num_training_steps=num_train_steps)\n",
    "    \n",
    "    ##Enable GPU if has\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "    \n",
    "    ## Start to training \n",
    "    torch.backends.cudnn.benchmark = True # tuning guide:https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html\n",
    "\n",
    "    loss_history = []\n",
    "    no_improvement = 0\n",
    "    PATIENCE=2\n",
    "    for _ in trange(int(params[\"NUM_TRAIN_EPOCHS\"]), desc=\"Epoch\"):\n",
    "        model.train()\n",
    "        tr_loss = 0\n",
    "        nb_tr_examples, nb_tr_steps = 0, 0\n",
    "\n",
    "        for step, batch in enumerate(tqdm(train_dataloader, desc=\"Training iteration\")):\n",
    "            batch = tuple(t.to(device) for t in batch)\n",
    "            input_ids, input_mask, segment_ids, label_ids = batch\n",
    "            #outputs = model(input_ids, attention_mask=input_mask, token_type_ids=segment_ids, labels=label_ids) # non-distillbert\n",
    "            outputs = model(input_ids, attention_mask=input_mask,labels=label_ids)\n",
    "            loss = outputs[0]\n",
    "\n",
    "            if params['GRADIENT_ACCUMULATION_STEPS'] > 1:\n",
    "                loss = loss / params['GRADIENT_ACCUMULATION_STEPS']\n",
    "\n",
    "            loss.backward()\n",
    "            tr_loss += loss.item()\n",
    "\n",
    "            if (step + 1) % params['GRADIENT_ACCUMULATION_STEPS'] == 0:\n",
    "                torch.nn.utils.clip_grad_norm_(model.parameters(),params['MAX_GRAD_NORM'])  \n",
    "\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad(set_to_none=True)\n",
    "                scheduler.step()\n",
    "        dev_loss, _, _ = evaluate(model, dev_dataloader)\n",
    "            #print(\"Dev loss:\", dev_loss)\n",
    "    \n",
    "        print(\"Loss history:\", loss_history)\n",
    "        print(\"Dev loss:\", dev_loss)\n",
    "\n",
    "        if len(loss_history) == 0 or dev_loss < min(loss_history):\n",
    "            no_improvement = 0\n",
    "            model_to_save = model.module if hasattr(model, 'module') else model\n",
    "            output_model_file = os.path.join(OUTPUT_DIR, MODEL_FILE_NAME)\n",
    "            torch.save(model_to_save.state_dict(), output_model_file)\n",
    "        else:\n",
    "            no_improvement += 1\n",
    "\n",
    "        if no_improvement >= PATIENCE: \n",
    "            print(\"No improvement on development set. Finish training.\")\n",
    "            break\n",
    "\n",
    "\n",
    "        loss_history.append(dev_loss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "63b9c70a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification,DistilBertForSequenceClassification\n",
    "from transformers import BertTokenizer,DistilBertTokenizer\n",
    "import os\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    "OUTPUT_DIR = \"./tmp/\"\n",
    "MODEL_FILE_NAME = \"pytorch_model.bin\"\n",
    "\n",
    "\n",
    "# Evaluate the dataset based on trained distilbert model\n",
    "def data_evaluation(texts,labels,model_name,params,trained=True,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME):\n",
    "    # Convert test data of submission to features\n",
    "    target_names = list(set(labels))\n",
    "    label2idx = {label: idx for idx, label in enumerate(target_names)}\n",
    "    \n",
    "    # Enable GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Select bert model\n",
    "    #BERT_MODEL = \"distilbert-base-uncased\"\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(model_name)\n",
    "       \n",
    "    if trained:\n",
    "        # Using trained model\n",
    "        model_state_dict = torch.load(os.path.join(OUTPUT_DIR, MODEL_FILE_NAME), map_location=lambda storage, loc: storage)\n",
    "        model=DistilBertForSequenceClassification.from_pretrained(model_name, state_dict=model_state_dict, num_labels = len(target_names),\n",
    "                                                                 output_attentions = False,\n",
    "                                                                 output_hidden_states = False)\n",
    "    else:\n",
    "        # Using pretrained model without training\n",
    "        model=DistilBertForSequenceClassification.from_pretrained(BERT_MODEL,num_labels = len(target_names),\n",
    "                                                                 output_attentions = False,\n",
    "                                                                 output_hidden_states = False)        \n",
    "    model.to(device)\n",
    "    \n",
    "    # Convert text and labels to embeddings \n",
    "    features = convert_examples_to_inputs(texts, labels, label2idx,  params['MAX_SEQ_LENGTH'], tokenizer)\n",
    "    dataloader = get_data_loader(features, params['MAX_SEQ_LENGTH'], params['BATCH_SIZE'], shuffle=False)\n",
    "    \n",
    "    # Predict the result, and discard the evaluatoin result, only take the prediction result.\n",
    "    _, correct, predicted = evaluate(model, dataloader)\n",
    "    print(\"Errors performance:\", precision_recall_fscore_support(correct, predicted, average=\"micro\"))\n",
    "\n",
    "    bert_accuracy = np.mean(predicted == correct)\n",
    "    \n",
    "    #print(bert_accuracy)\n",
    "    print(classification_report(correct, predicted))\n",
    "\n",
    "    return correct,predicted, bert_accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f43ef8bb",
   "metadata": {},
   "source": [
    "##### Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d88cb406",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# load train data\n",
    "source_train_data_path=\"./01_data/WikiLarge_Train.csv\"\n",
    "source_train_data=pd.read_csv(source_train_data_path)\n",
    "\n",
    "RANDOM_STATE=1\n",
    "PORTION=0.01\n",
    "size=round(len(source_train_data)*PORTION)\n",
    "train_data=source_train_data.sample(n=size,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e982e3da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 0, 'length')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Plot histogram with the length. Truncate max length to 5000 tokens.\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "train_data['length'] = train_data['original_text'].apply(lambda x: len(x.split()))\n",
    "sns.distplot(train_data[train_data['length'] < 5000]['length'])\n",
    "plt.title('Frequence of sentences of a given length', fontsize=14)\n",
    "plt.xlabel('length', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3135c022",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count    4168.000000\n",
      "mean       21.913628\n",
      "std        12.775337\n",
      "min         1.000000\n",
      "25%        13.000000\n",
      "50%        20.000000\n",
      "75%        29.000000\n",
      "max        79.000000\n",
      "Name: original_text, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# BERT token length should not be more than 512.\n",
    "data_describe=train_data['original_text'].apply(lambda x: len(x.split())).describe()\n",
    "print(data_describe)\n",
    "MAX_SEQ_LENGTH=int(data_describe['max'])\n",
    "if MAX_SEQ_LENGTH>512:\n",
    "    MAX_SEQ_LENGTH=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c5caba0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1}\n",
      "Train size: 3375\n",
      "Dev size: 376\n",
      "Test size: 417\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(train_texts,dev_texts,test_texts),(train_labels,dev_labels,test_labels),(target_names,label2idx)=train_dev_test(train_data,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2c2e6f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "params={\n",
    "        \"GRADIENT_ACCUMULATION_STEPS\":1,\n",
    "        \"NUM_TRAIN_EPOCHS\":8,\n",
    "        \"LEARNING_RATE\":2e-5,\n",
    "        \"WARMUP_PROPORTION\":0.1,\n",
    "        \"MAX_GRAD_NORM\":5,\n",
    "        \"MAX_SEQ_LENGTH\":MAX_SEQ_LENGTH,\n",
    "        \"BATCH_SIZE\":16,\n",
    "        \"NUM_WARMUP_STEPS\":600\n",
    "}\n",
    "BERT_MODEL = \"distilbert-base-uncased\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "228c8665",
   "metadata": {},
   "source": [
    "##### Initial accuracy for pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d026f946",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ce8b9da041d45f7ba5a77556a9ee258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors performance: (0.5227817745803357, 0.5227817745803357, 0.5227817745803357, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.41      0.04      0.07       196\n",
      "           1       0.53      0.95      0.68       221\n",
      "\n",
      "    accuracy                           0.52       417\n",
      "   macro avg       0.47      0.50      0.37       417\n",
      "weighted avg       0.47      0.52      0.39       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_,_,init_acc=data_evaluation(test_texts,test_labels,BERT_MODEL,params,trained=False,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f69004e9",
   "metadata": {},
   "source": [
    "##### Train model without any preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c4de7ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                     | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fffa25cc5e6f4265978dee52f5753dbc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49373c820e8a4d6d80b3035a02490e8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: []\n",
      "Dev loss: 0.6223116430143515\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  12%|█████████▋                                                                   | 1/8 [00:40<04:44, 40.63s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f4b618ed5175428bb46045850007c494",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9309498f8d0b4080beaee10aee870189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|███████████████████▎                                                         | 2/8 [01:20<04:00, 40.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: [0.6223116430143515]\n",
      "Dev loss: 0.6304677041868368\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f3c41366d44cd48dfc96233d73cbab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d31ee16203ec4880adc066254ee225ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|███████████████████▎                                                         | 2/8 [02:00<06:00, 60.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: [0.6223116430143515, 0.6304677041868368]\n",
      "Dev loss: 0.6753258295357227\n",
      "No improvement on development set. Finish training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(BERT_MODEL,train_texts,train_labels,dev_texts,dev_labels,target_names,label2idx,params)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f40858b",
   "metadata": {},
   "source": [
    "##### Accuracy after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4beb3298",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7363e341b2a44e71bf3ebb54f5ba4181",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors performance: (0.6666666666666666, 0.6666666666666666, 0.6666666666666666, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.67      0.65       196\n",
      "           1       0.69      0.67      0.68       221\n",
      "\n",
      "    accuracy                           0.67       417\n",
      "   macro avg       0.67      0.67      0.67       417\n",
      "weighted avg       0.67      0.67      0.67       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_,_,orig_acc=data_evaluation(test_texts,test_labels,BERT_MODEL,params,trained=True,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f866ef2",
   "metadata": {},
   "source": [
    "##### Remove stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3f02461f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\patri\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from text_preprocessing import preprocess_text\n",
    "from text_preprocessing import remove_punctuation,remove_special_character,normalize_unicode,check_spelling,remove_stopword,lemmatize_word\n",
    "# Preprocess text using custom preprocess functions in the pipeline \n",
    "#STOPWORDS=['-RRB-','-LRB-'] # remove customized stopwords\n",
    "#preprocess_functions = [to_lower, remove_punctuation,remove_special_character,normalize_unicode,remove_stopword,lemmatize_word]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b99a2ea3",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data=train_data.copy()\n",
    "process_data['original_text'] = process_data['original_text'].apply(lambda x:' '.join(remove_stopword(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4096def9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314316</th>\n",
       "      <td>The Yarra Trams fleet consists 500 trams , ope...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136396</th>\n",
       "      <td>Still Life concept album , explained Åkerfeldt...</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377680</th>\n",
       "      <td>Romana , short Romanadvoratrelundar , fictiona...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280270</th>\n",
       "      <td>A minor scale music theory scale least three s...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285587</th>\n",
       "      <td>The show also created character Frasier Crane .</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145077</th>\n",
       "      <td>In paintball , bunker obstacle field play used...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35542</th>\n",
       "      <td>La Ferrière-Harang commune Calvados department...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238435</th>\n",
       "      <td>The British Rail Class 325 dual-voltage altern...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324621</th>\n",
       "      <td>When Palmengarten returned city 's control 196...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38232</th>\n",
       "      <td>Pong -LRB- marketed PONG -RRB- one earliest ar...</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4168 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  label  length\n",
       "314316  The Yarra Trams fleet consists 500 trams , ope...      0      18\n",
       "136396  Still Life concept album , explained Åkerfeldt...      1      39\n",
       "377680  Romana , short Romanadvoratrelundar , fictiona...      0      20\n",
       "280270  A minor scale music theory scale least three s...      0      35\n",
       "285587    The show also created character Frasier Crane .      0       9\n",
       "...                                                   ...    ...     ...\n",
       "145077  In paintball , bunker obstacle field play used...      1      25\n",
       "35542   La Ferrière-Harang commune Calvados department...      1      17\n",
       "238435  The British Rail Class 325 dual-voltage altern...      0      26\n",
       "324621  When Palmengarten returned city 's control 196...      0      21\n",
       "38232   Pong -LRB- marketed PONG -RRB- one earliest ar...      1      52\n",
       "\n",
       "[4168 rows x 3 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "81320b13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1}\n",
      "Train size: 3375\n",
      "Dev size: 376\n",
      "Test size: 417\n"
     ]
    }
   ],
   "source": [
    "(train_texts,dev_texts,test_texts),(train_labels,dev_labels,test_labels),(target_names,label2idx)=train_dev_test(process_data,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2f11b57e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                     | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2ff68dbce68d417a93410e59425a0fbd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2d1b1d20bea4f35b168bb087aa7ce50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: []\n",
      "Dev loss: 0.6449858819444975\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  12%|█████████▋                                                                   | 1/8 [00:40<04:43, 40.53s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "46bab807262a481ba92250839f95edc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1dedae58dbd9469698d2f8058a4b6f54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: [0.6449858819444975]\n",
      "Dev loss: 0.5820029315849146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|███████████████████▎                                                         | 2/8 [01:20<04:02, 40.43s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcdbb549740b4584b63028af35d21a95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ebf0a0a494c492c8158b751ec972ca9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  38%|████████████████████████████▉                                                | 3/8 [02:00<03:19, 39.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: [0.6449858819444975, 0.5820029315849146]\n",
      "Dev loss: 0.6511865258216858\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d98364c0946142e29c601b89904327d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "861e054f8a324cba87e5638927fb584b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  38%|████████████████████████████▉                                                | 3/8 [02:40<04:27, 53.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: [0.6449858819444975, 0.5820029315849146, 0.6511865258216858]\n",
      "Dev loss: 0.8664342053234577\n",
      "No improvement on development set. Finish training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(BERT_MODEL,train_texts,train_labels,dev_texts,dev_labels,target_names,label2idx,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "78d0cb7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25a4696ccab741d8ab91c4e0f5d58826",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors performance: (0.6786570743405276, 0.6786570743405276, 0.6786570743405276, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.60      0.64       196\n",
      "           1       0.68      0.75      0.71       221\n",
      "\n",
      "    accuracy                           0.68       417\n",
      "   macro avg       0.68      0.67      0.67       417\n",
      "weighted avg       0.68      0.68      0.68       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_,_,sw_acc=data_evaluation(test_texts,test_labels,BERT_MODEL,params,trained=True,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "031671e3",
   "metadata": {},
   "source": [
    "##### Spelling correction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d46e4ed3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type('dfdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7f524f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data=train_data.copy()\n",
    "process_data['original_text'] = process_data['original_text'].apply(lambda x:' '.join(check_spelling(x)) if type(x)=='str' else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aa8581c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314316</th>\n",
       "      <td>The Yarra Trams fleet consists of 500 trams , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136396</th>\n",
       "      <td>Still Life is a concept album , as explained b...</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377680</th>\n",
       "      <td>Romana , short for Romanadvoratrelundar , is a...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280270</th>\n",
       "      <td>A minor scale in music theory is any scale tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285587</th>\n",
       "      <td>The show also created the character Frasier Cr...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145077</th>\n",
       "      <td>In paintball , a bunker is an obstacle on the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35542</th>\n",
       "      <td>La Ferrière-Harang is a commune in the Calvado...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238435</th>\n",
       "      <td>The British Rail Class 325 is a dual-voltage a...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324621</th>\n",
       "      <td>When the Palmengarten was returned to the city...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38232</th>\n",
       "      <td>Pong -LRB- marketed as PONG -RRB- is one of th...</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4168 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  label  length\n",
       "314316  The Yarra Trams fleet consists of 500 trams , ...      0      18\n",
       "136396  Still Life is a concept album , as explained b...      1      39\n",
       "377680  Romana , short for Romanadvoratrelundar , is a...      0      20\n",
       "280270  A minor scale in music theory is any scale tha...      0      35\n",
       "285587  The show also created the character Frasier Cr...      0       9\n",
       "...                                                   ...    ...     ...\n",
       "145077  In paintball , a bunker is an obstacle on the ...      1      25\n",
       "35542   La Ferrière-Harang is a commune in the Calvado...      1      17\n",
       "238435  The British Rail Class 325 is a dual-voltage a...      0      26\n",
       "324621  When the Palmengarten was returned to the city...      0      21\n",
       "38232   Pong -LRB- marketed as PONG -RRB- is one of th...      1      52\n",
       "\n",
       "[4168 rows x 3 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "33f534ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1}\n",
      "Train size: 3375\n",
      "Dev size: 376\n",
      "Test size: 417\n"
     ]
    }
   ],
   "source": [
    "(train_texts,dev_texts,test_texts),(train_labels,dev_labels,test_labels),(target_names,label2idx)=train_dev_test(process_data,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b608b890",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                     | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1532441b7f4b0fae5d0760f344d6b9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8fbb83ec5f243b7b00f4e20f5acde48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: []\n",
      "Dev loss: 0.6348510943353176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  12%|█████████▋                                                                   | 1/8 [00:40<04:46, 40.88s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bde748ae24574a6a9e4f4d9d3aff9010",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df108c87acc844b0a0687e54a1c351e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: [0.6348510943353176]\n",
      "Dev loss: 0.5921247117221355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|███████████████████▎                                                         | 2/8 [01:21<04:04, 40.79s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1aee949519a54615a9e2bdf27d71aad5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91157b8fdb6c4e46a0b053318cd25f32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  38%|████████████████████████████▉                                                | 3/8 [02:01<03:21, 40.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: [0.6348510943353176, 0.5921247117221355]\n",
      "Dev loss: 0.6170806580533584\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7d2d7058390941c188b5a1c616d6872f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae44167a8d234bdcb3b44c307df33ee6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  38%|████████████████████████████▉                                                | 3/8 [02:41<04:29, 53.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: [0.6348510943353176, 0.5921247117221355, 0.6170806580533584]\n",
      "Dev loss: 0.9130118054648241\n",
      "No improvement on development set. Finish training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(BERT_MODEL,train_texts,train_labels,dev_texts,dev_labels,target_names,label2idx,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb9bbc2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3fc9f58619884ba9b097b5205f6e3cae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors performance: (0.6546762589928058, 0.6546762589928058, 0.6546762589928058, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      0.69      0.65       196\n",
      "           1       0.70      0.62      0.66       221\n",
      "\n",
      "    accuracy                           0.65       417\n",
      "   macro avg       0.66      0.66      0.65       417\n",
      "weighted avg       0.66      0.65      0.65       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_,_,pc_acc=data_evaluation(test_texts,test_labels,BERT_MODEL,params,trained=True,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bd88bcc",
   "metadata": {},
   "source": [
    "##### Lemmatization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c77e6a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data=train_data.copy()\n",
    "process_data['original_text'] = process_data['original_text'].apply(lambda x:' '.join(lemmatize_word(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6c8e7217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "314316    The Yarra Trams fleet consists of 500 tram , o...\n",
       "136396    Still Life is a concept album , a explained by...\n",
       "377680    Romana , short for Romanadvoratrelundar , is a...\n",
       "280270    A minor scale in music theory is any scale tha...\n",
       "285587    The show also created the character Frasier Cr...\n",
       "                                ...                        \n",
       "145077    In paintball , a bunker is an obstacle on the ...\n",
       "35542     La Ferrière-Harang is a commune in the Calvado...\n",
       "238435    The British Rail Class 325 is a dual-voltage a...\n",
       "324621    When the Palmengarten wa returned to the city ...\n",
       "38232     Pong -LRB- marketed a PONG -RRB- is one of the...\n",
       "Name: original_text, Length: 4168, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_data['original_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f5fb8b26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1}\n",
      "Train size: 3375\n",
      "Dev size: 376\n",
      "Test size: 417\n"
     ]
    }
   ],
   "source": [
    "(train_texts,dev_texts,test_texts),(train_labels,dev_labels,test_labels),(target_names,label2idx)=train_dev_test(process_data,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba27962d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                     | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c71ef6ea13164181a5e6a1adb4563482",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca020a44c0d946ab815b3ec8342e3338",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: []\n",
      "Dev loss: 0.6362876519560814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  12%|█████████▋                                                                   | 1/8 [00:41<04:47, 41.05s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da9e806f1e3942158e2671b6a367f5aa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39e6bf31584c4768b94ffdf7a00122f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: [0.6362876519560814]\n",
      "Dev loss: 0.5928014839688936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|███████████████████▎                                                         | 2/8 [01:21<04:05, 40.88s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e7b22ea14fa4eacbb11c5643b971f19",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a0100433d5e419aa0ff4c214e6604c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  38%|████████████████████████████▉                                                | 3/8 [02:01<03:22, 40.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: [0.6362876519560814, 0.5928014839688936]\n",
      "Dev loss: 0.6533676118900379\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3bed7ae76c4f219120a9f1b0608709",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ed5cf183920345099e3eba1579e8cfb6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  38%|████████████████████████████▉                                                | 3/8 [02:41<04:29, 53.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: [0.6362876519560814, 0.5928014839688936, 0.6533676118900379]\n",
      "Dev loss: 1.0288410174349945\n",
      "No improvement on development set. Finish training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(BERT_MODEL,train_texts,train_labels,dev_texts,dev_labels,target_names,label2idx,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "23954a9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5720abae0c8b45dc8cafe095d98e36f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors performance: (0.6762589928057554, 0.6762589928057554, 0.6762589928057554, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      0.67      0.66       196\n",
      "           1       0.70      0.68      0.69       221\n",
      "\n",
      "    accuracy                           0.68       417\n",
      "   macro avg       0.68      0.68      0.68       417\n",
      "weighted avg       0.68      0.68      0.68       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_,_,lm_acc=data_evaluation(test_texts,test_labels,BERT_MODEL,params,trained=True,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8bf41f",
   "metadata": {},
   "source": [
    "##### Check the duplicated data and create the data set without duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "767783f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_unique=train_data.copy()\n",
    "train_data_unique['duplicated']=train_data_unique.duplicated(subset=['original_text'])\n",
    "#train_data_unique=train_data[train_data['duplicated']==False]\n",
    "#print(\"Duplicated records: %.2f%%\" %(100*(len(train_data)-len(train_data_unique))/len(train_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f66e4835",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "      <th>length</th>\n",
       "      <th>duplicated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>314316</th>\n",
       "      <td>The Yarra Trams fleet consists of 500 trams , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136396</th>\n",
       "      <td>Still Life is a concept album , as explained b...</td>\n",
       "      <td>1</td>\n",
       "      <td>39</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377680</th>\n",
       "      <td>Romana , short for Romanadvoratrelundar , is a...</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280270</th>\n",
       "      <td>A minor scale in music theory is any scale tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285587</th>\n",
       "      <td>The show also created the character Frasier Cr...</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145077</th>\n",
       "      <td>In paintball , a bunker is an obstacle on the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35542</th>\n",
       "      <td>La Ferrière-Harang is a commune in the Calvado...</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238435</th>\n",
       "      <td>The British Rail Class 325 is a dual-voltage a...</td>\n",
       "      <td>0</td>\n",
       "      <td>26</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324621</th>\n",
       "      <td>When the Palmengarten was returned to the city...</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38232</th>\n",
       "      <td>Pong -LRB- marketed as PONG -RRB- is one of th...</td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4168 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            original_text  label  length  \\\n",
       "314316  The Yarra Trams fleet consists of 500 trams , ...      0      18   \n",
       "136396  Still Life is a concept album , as explained b...      1      39   \n",
       "377680  Romana , short for Romanadvoratrelundar , is a...      0      20   \n",
       "280270  A minor scale in music theory is any scale tha...      0      35   \n",
       "285587  The show also created the character Frasier Cr...      0       9   \n",
       "...                                                   ...    ...     ...   \n",
       "145077  In paintball , a bunker is an obstacle on the ...      1      25   \n",
       "35542   La Ferrière-Harang is a commune in the Calvado...      1      17   \n",
       "238435  The British Rail Class 325 is a dual-voltage a...      0      26   \n",
       "324621  When the Palmengarten was returned to the city...      0      21   \n",
       "38232   Pong -LRB- marketed as PONG -RRB- is one of th...      1      52   \n",
       "\n",
       "        duplicated  \n",
       "314316       False  \n",
       "136396       False  \n",
       "377680       False  \n",
       "280270       False  \n",
       "285587       False  \n",
       "...            ...  \n",
       "145077       False  \n",
       "35542        False  \n",
       "238435       False  \n",
       "324621       False  \n",
       "38232        False  \n",
       "\n",
       "[4168 rows x 4 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d1022835",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data=train_data_unique.copy()\n",
    "process_data=process_data[(process_data['duplicated']==False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c5a2d666",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1}\n",
      "Train size: 3319\n",
      "Dev size: 369\n",
      "Test size: 410\n"
     ]
    }
   ],
   "source": [
    "(train_texts,dev_texts,test_texts),(train_labels,dev_labels,test_labels),(target_names,label2idx)=train_dev_test(process_data,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5e9cae0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                     | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ac26354692c432f8eb4a85fa710bc96",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcede95f4f904dbea0a3f4d9a8b4fa6d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: []\n",
      "Dev loss: 0.6140957226355871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  12%|█████████▋                                                                   | 1/8 [00:40<04:42, 40.39s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58e4f3487e01403e839b22bbfc601188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45a2acb6261144dea25a0c94dfdbd096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: [0.6140957226355871]\n",
      "Dev loss: 0.5418222869435946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|███████████████████▎                                                         | 2/8 [01:20<04:01, 40.32s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8116044bbd34e7282a992990e084e80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acaf718f79fe4065a82a7032dba1b3d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  38%|████████████████████████████▉                                                | 3/8 [01:59<03:19, 39.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: [0.6140957226355871, 0.5418222869435946]\n",
      "Dev loss: 0.6547409277409315\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2410dff802346f0b8bed6bde73bd54c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/208 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e387bc05172243a4859ff3bf3641664c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  38%|████████████████████████████▉                                                | 3/8 [02:39<04:25, 53.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: [0.6140957226355871, 0.5418222869435946, 0.6547409277409315]\n",
      "Dev loss: 1.0030118270466726\n",
      "No improvement on development set. Finish training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(BERT_MODEL,train_texts,train_labels,dev_texts,dev_labels,target_names,label2idx,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "caa91be4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afb8512c717745dbb5eae3436d160f2a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/26 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors performance: (0.6707317073170732, 0.6707317073170732, 0.6707317073170732, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.65      0.66       201\n",
      "           1       0.67      0.69      0.68       209\n",
      "\n",
      "    accuracy                           0.67       410\n",
      "   macro avg       0.67      0.67      0.67       410\n",
      "weighted avg       0.67      0.67      0.67       410\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_,_,dup_acc=data_evaluation(test_texts,test_labels,BERT_MODEL,params,trained=True,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39051967",
   "metadata": {},
   "source": [
    "##### Remove the records which have the different labels\n",
    "The sentences with different labels should impact the train performance as well as prediction results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "621ce4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# look for the records with different labels \n",
    "def duple_labels(data):\n",
    "    df_by=pd.DataFrame(data.groupby(['original_text','label']).count().reset_index()[[\"original_text\",\"label\"]])\n",
    "    df_by=df_by.groupby(by='original_text').count().sort_values('label',ascending=False).reset_index()\n",
    "    diff_labels=df_by[df_by['label']>1]\n",
    "    print(\"Records with different labels: %.2f%%\" %(100*len(diff_labels)/len(data)))\n",
    "    return diff_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6f886a9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Records with different labels: 0.02%\n"
     ]
    }
   ],
   "source": [
    "df_duple_labels=duple_labels(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9b3d15d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Indentify double labels in data\n",
    "train_data_unique=train_data_unique.merge(df_duple_labels,how=\"left\",left_on=\"original_text\",right_on=\"original_text\")\n",
    "train_data_unique['label_y']=train_data_unique['label_y'].apply(lambda x: '0' if pd.isnull(x) else '1') # 0 means 1 label, 1 means 2 labels\n",
    "train_data_unique=pd.DataFrame(train_data_unique[['original_text','label_x','label_y','duplicated']])\n",
    "train_data_unique.columns=['original_text','label','dulabel','duplicated']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25546482",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "      <th>dulabel</th>\n",
       "      <th>duplicated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Yarra Trams fleet consists of 500 trams , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Still Life is a concept album , as explained b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Romana , short for Romanadvoratrelundar , is a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A minor scale in music theory is any scale tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The show also created the character Frasier Cr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>In paintball , a bunker is an obstacle on the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4164</th>\n",
       "      <td>La Ferrière-Harang is a commune in the Calvado...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>The British Rail Class 325 is a dual-voltage a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4166</th>\n",
       "      <td>When the Palmengarten was returned to the city...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167</th>\n",
       "      <td>Pong -LRB- marketed as PONG -RRB- is one of th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4168 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          original_text  label dulabel  \\\n",
       "0     The Yarra Trams fleet consists of 500 trams , ...      0       0   \n",
       "1     Still Life is a concept album , as explained b...      1       0   \n",
       "2     Romana , short for Romanadvoratrelundar , is a...      0       0   \n",
       "3     A minor scale in music theory is any scale tha...      0       0   \n",
       "4     The show also created the character Frasier Cr...      0       0   \n",
       "...                                                 ...    ...     ...   \n",
       "4163  In paintball , a bunker is an obstacle on the ...      1       0   \n",
       "4164  La Ferrière-Harang is a commune in the Calvado...      1       0   \n",
       "4165  The British Rail Class 325 is a dual-voltage a...      0       0   \n",
       "4166  When the Palmengarten was returned to the city...      0       0   \n",
       "4167  Pong -LRB- marketed as PONG -RRB- is one of th...      1       0   \n",
       "\n",
       "      duplicated  \n",
       "0          False  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  \n",
       "...          ...  \n",
       "4163       False  \n",
       "4164       False  \n",
       "4165       False  \n",
       "4166       False  \n",
       "4167       False  \n",
       "\n",
       "[4168 rows x 4 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c762bfe",
   "metadata": {},
   "source": [
    "##### Accuracy of removing records with duplicate text or different label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "921b8793",
   "metadata": {},
   "outputs": [],
   "source": [
    "process_data=train_data_unique.copy()\n",
    "process_data=process_data[(process_data['dulabel']=='0')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "bf88e2b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original_text</th>\n",
       "      <th>label</th>\n",
       "      <th>dulabel</th>\n",
       "      <th>duplicated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Yarra Trams fleet consists of 500 trams , ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Still Life is a concept album , as explained b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Romana , short for Romanadvoratrelundar , is a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A minor scale in music theory is any scale tha...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The show also created the character Frasier Cr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4163</th>\n",
       "      <td>In paintball , a bunker is an obstacle on the ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4164</th>\n",
       "      <td>La Ferrière-Harang is a commune in the Calvado...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4165</th>\n",
       "      <td>The British Rail Class 325 is a dual-voltage a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4166</th>\n",
       "      <td>When the Palmengarten was returned to the city...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4167</th>\n",
       "      <td>Pong -LRB- marketed as PONG -RRB- is one of th...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4165 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          original_text  label dulabel  \\\n",
       "0     The Yarra Trams fleet consists of 500 trams , ...      0       0   \n",
       "1     Still Life is a concept album , as explained b...      1       0   \n",
       "2     Romana , short for Romanadvoratrelundar , is a...      0       0   \n",
       "3     A minor scale in music theory is any scale tha...      0       0   \n",
       "4     The show also created the character Frasier Cr...      0       0   \n",
       "...                                                 ...    ...     ...   \n",
       "4163  In paintball , a bunker is an obstacle on the ...      1       0   \n",
       "4164  La Ferrière-Harang is a commune in the Calvado...      1       0   \n",
       "4165  The British Rail Class 325 is a dual-voltage a...      0       0   \n",
       "4166  When the Palmengarten was returned to the city...      0       0   \n",
       "4167  Pong -LRB- marketed as PONG -RRB- is one of th...      1       0   \n",
       "\n",
       "      duplicated  \n",
       "0          False  \n",
       "1          False  \n",
       "2          False  \n",
       "3          False  \n",
       "4          False  \n",
       "...          ...  \n",
       "4163       False  \n",
       "4164       False  \n",
       "4165       False  \n",
       "4166       False  \n",
       "4167       False  \n",
       "\n",
       "[4165 rows x 4 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "7bb7e9bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1}\n",
      "Train size: 3373\n",
      "Dev size: 375\n",
      "Test size: 417\n"
     ]
    }
   ],
   "source": [
    "(train_texts,dev_texts,test_texts),(train_labels,dev_labels,test_labels),(target_names,label2idx)=train_dev_test(process_data,random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dfe8d806",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_layer_norm.weight', 'vocab_transform.bias', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "Epoch:   0%|                                                                                     | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b35a40c9263d4384baf3934bebe3f721",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb71479c2f7d476397ebe9817bbb6882",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: []\n",
      "Dev loss: 0.6254049700995287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  12%|█████████▋                                                                   | 1/8 [00:40<04:46, 40.88s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7db65534a294f519a0c9bfcaf742295",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1176cb2a1f4c411b954ffa741cc0f6f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: [0.6254049700995287]\n",
      "Dev loss: 0.5567222212751707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  25%|███████████████████▎                                                         | 2/8 [01:21<04:05, 40.84s/it]"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ace65aaede242cbad6a5b1006b05de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad58690f6af34e3c9e6433fea570162f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  38%|████████████████████████████▉                                                | 3/8 [02:01<03:22, 40.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: [0.6254049700995287, 0.5567222212751707]\n",
      "Dev loss: 0.5894718704124292\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "23a044b0c65a4bd8b2676ba253b6a573",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training iteration:   0%|          | 0/211 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27afee87745e4b0eb1c5cf35916eef9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch:  38%|████████████████████████████▉                                                | 3/8 [02:41<04:29, 53.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss history: [0.6254049700995287, 0.5567222212751707, 0.5894718704124292]\n",
      "Dev loss: 0.8305967810253302\n",
      "No improvement on development set. Finish training.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train(BERT_MODEL,train_texts,train_labels,dev_texts,dev_labels,target_names,label2idx,params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "67f7bacc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ff4219824fa408d99119966f977c44d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluation iteration:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Errors performance: (0.697841726618705, 0.697841726618705, 0.697841726618705, None)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.68      0.69       209\n",
      "           1       0.69      0.71      0.70       208\n",
      "\n",
      "    accuracy                           0.70       417\n",
      "   macro avg       0.70      0.70      0.70       417\n",
      "weighted avg       0.70      0.70      0.70       417\n",
      "\n"
     ]
    }
   ],
   "source": [
    "_,_,duo_acc=data_evaluation(test_texts,test_labels,BERT_MODEL,params,trained=True,OUTPUT_DIR = OUTPUT_DIR, MODEL_FILE_NAME = MODEL_FILE_NAME)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ad5940",
   "metadata": {},
   "source": [
    "##### Compare the results from different text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3e2094b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_acc=pd.DataFrame(columns=['description','accuracy'])\n",
    "df_acc['description']=['Pretrain','Fine tune without preprocessing',\n",
    "                       'Removal of stopwords','Correction of spelling',\n",
    "                      'Lemmatization','Removal of duplicate records',\n",
    "                      'Removal of mislabeling']\n",
    "df_acc['accuracy']=[init_acc,orig_acc,sw_acc,pc_acc,lm_acc,dup_acc,duo_acc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8eacf29d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='accuracy', ylabel='description'>"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(data=df_acc, y=\"description\", x=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a514b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_data['duplicated']=error_data.duplicated(subset=['original_text'])\n",
    "error_data_unique=error_data[error_data['duplicated']==False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8fe47f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_data_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f248fba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataframe with corrected \n",
    "test_full=test_data_unique.merge(error_data_unique,how=\"left\",left_on=\"original_text\",right_on=\"original_text\")\n",
    "test_full['label_y']=test_full['label_y'].apply(lambda x: '1' if pd.isnull(x) else '0')\n",
    "test_full['duplicated']=test_full.duplicated(subset=['original_text'])\n",
    "test_full_unique=test_full[test_full['duplicated']==False]\n",
    "test_full=pd.DataFrame(test_full[['original_text','label_x','label_y','duplicated','dulabel']])\n",
    "test_full.columns=['original_text','label','correct','duplicated','dulabel']\n",
    "test_full"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6093b67f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_full.to_csv(\"./00_error_analysis/test_full.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409061c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# TRAIN SET \n",
    "test_full['original_text'].apply(lambda x: len(x.split())).plot(kind='hist');\n",
    "plt.yscale('log');\n",
    "plt.title('Distribution of original text length in words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "554f9032",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_data['original_text'].apply(lambda x: len(x.split())).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ad857e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9ece0e",
   "metadata": {},
   "source": [
    "### Rerun the prediction to confirm the errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636566a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# import bert test error data\n",
    "error_data_path=\"./tmp/test_error_2022-10-13.csv\"\n",
    "error_data=pd.read_csv(error_data_path)\n",
    "\n",
    "# import bert full test data\n",
    "test_data_path=\"./tmp/test_full_2022-10-13.csv\"\n",
    "test_data=pd.read_csv(test_data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2ed0826",
   "metadata": {},
   "source": [
    "##### Import 2 models for comparison: fine tuning model, and pretrained model without fine tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8343b87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    target_names = list(set(test_full['label']))\n",
    "    label2idx = {label: idx for idx, label in enumerate(target_names)}\n",
    "    \n",
    "    # Enable GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    \n",
    "    # Select bert model\n",
    "    BERT_MODEL = \"distilbert-base-uncased\"\n",
    "    tokenizer = DistilBertTokenizer.from_pretrained(BERT_MODEL)\n",
    "    \n",
    "    # Using trained model\n",
    "    model_state_dict = torch.load(os.path.join(OUTPUT_DIR, MODEL_FILE_NAME), map_location=lambda storage, loc: storage)\n",
    "    model=DistilBertForSequenceClassification.from_pretrained(BERT_MODEL, state_dict=model_state_dict, num_labels = len(target_names),\n",
    "                                                             output_attentions = False,\n",
    "                                                             output_hidden_states = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ca99675",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Select bert model\n",
    "    BERT_MODEL = \"distilbert-base-uncased\"\n",
    "    v_tokenizer = DistilBertTokenizer.from_pretrained(BERT_MODEL)\n",
    "    \n",
    "    # Using trained model\n",
    "    v_model=DistilBertForSequenceClassification.from_pretrained(BERT_MODEL,num_labels = len(target_names),\n",
    "                                                             output_attentions = False,\n",
    "                                                             output_hidden_states = False)   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4491211",
   "metadata": {},
   "source": [
    "Check result on pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f9544b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#str_to_predict = \"olawe\"\n",
    "str_to_predict = \"He also worked extensively on animal behavior -LRB- ethology -RRB- .\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1caee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = convert_examples_to_inputs([str_to_predict],[1], label2idx, MAX_SEQ_LENGTH, v_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6eb895",
   "metadata": {},
   "outputs": [],
   "source": [
    "v_tokenizer.tokenize(str_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfe848e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = v_tokenizer(str_to_predict, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = v_model(**inputs).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "v_model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a066fd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "258bfb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lime\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from lime.lime_text import LimeTextExplainer\n",
    "\n",
    "def predictor(texts):\n",
    "    with torch.no_grad():\n",
    "        outputs = v_model(**v_tokenizer(texts, return_tensors=\"pt\", padding=True))\n",
    "        #print(outputs.logits)\n",
    "        probas = F.softmax(outputs.logits,dim=1).detach().numpy()\n",
    "    return probas\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=target_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9f05793",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(str_to_predict, predictor, num_features=200, num_samples=20)\n",
    "exp.show_in_notebook(text=str_to_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5bc80e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers_interpret import SequenceClassificationExplainer\n",
    "cls_explainer = SequenceClassificationExplainer(\n",
    "    v_model,\n",
    "    v_tokenizer)\n",
    "word_attributions = cls_explainer(str_to_predict)\n",
    "word_attributions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d47cb7b",
   "metadata": {},
   "source": [
    " Check result on fine tuning model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6340ac08",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = tokenizer(str_to_predict, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    logits = model(**inputs).logits\n",
    "\n",
    "predicted_class_id = logits.argmax().item()\n",
    "model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "826fd98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predictor(texts):\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**tokenizer(texts, return_tensors=\"pt\", padding=True))\n",
    "        #print(outputs.logits)\n",
    "        probas = F.softmax(outputs.logits,dim=1).detach().numpy()\n",
    "    return probas\n",
    "\n",
    "explainer = LimeTextExplainer(class_names=target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f24d7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = explainer.explain_instance(str_to_predict, predictor, num_features=200, num_samples=20)\n",
    "exp.show_in_notebook(text=str_to_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "000f0a23",
   "metadata": {},
   "source": [
    "The above presents the fine tuning process actually changed the prediction result. That could be caused by:\n",
    "- The word is attributed to be difficultly understood.\n",
    "- The similar words or sentence are trained as difficult one.\n",
    "\n",
    "Thus, the next tasks are to confirm the aboves."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c64237",
   "metadata": {},
   "source": [
    "##### Sentencebert to find the similiar sentences to check whether the similiar sentences may impact the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4093374",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "onlinemodel='all-mpnet-base-v2'\n",
    "embedder = SentenceTransformer(onlinemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed1824",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load training data\n",
    "train_data_path=\"./01_data/WikiLarge_Train.csv\"\n",
    "train_data=pd.read_csv(train_data_path)\n",
    "texts=train_data['original_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87784d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.exists(\"./tmp/embeddings.csv\"):\n",
    "    query_embeddings= np.loadtxt(\"./tmp/embeddings.csv\", delimiter=\",\")\n",
    "else:\n",
    "    # Sampling data given the full train data volume is big\n",
    "    query_embeddings=embedder.encode(texts)\n",
    "    np.savetxt(\"./tmp/embeddings.csv\", query_embeddings, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447edc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# work out the similarity and identify the record of self\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "sim=cosine_similarity([embedder.encode(str_to_predict)],query_embeddings)\n",
    "j=np.argmax(sim)\n",
    "#sim.argsort()[-3:][::-1][0][:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73b7b321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# produce the fine tuning dataset\n",
    "f_texts=[]\n",
    "f_labels=[]\n",
    "for i in np.where(sim[0]>0.7)[0]:\n",
    "    if i!=j:\n",
    "        f_texts.append(train_data.iloc[i]['original_text'])\n",
    "        f_labels.append(train_data.iloc[i]['label'])\n",
    "    #print(i,train_data.iloc[i]['label'].values,train_data.iloc[i]['original_text'].values,sim[0][i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34def62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4c4158",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_labels.count(1),f_labels.count(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fa77d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ba41c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_labels=[1,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1d39df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb7f06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "678a062f",
   "metadata": {},
   "source": [
    "Fine tuning the pretrained model with the above similar data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d732fe8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "    # Select bert model\n",
    "    BERT_MODEL = \"distilbert-base-uncased\"\n",
    "    f_tokenizer = DistilBertTokenizer.from_pretrained(BERT_MODEL)\n",
    "    \n",
    "    # Using trained model\n",
    "    f_model=DistilBertForSequenceClassification.from_pretrained(BERT_MODEL,num_labels = len(target_names),\n",
    "                                                             output_attentions = False,\n",
    "                                                             output_hidden_states = False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86d1903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert selected data into training set\n",
    "f_features = convert_examples_to_inputs(f_texts,f_labels, label2idx, MAX_SEQ_LENGTH, f_tokenizer)\n",
    "f_train_dataloader = get_data_loader(f_features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c9d090b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW,get_linear_schedule_with_warmup\n",
    "\n",
    "GRADIENT_ACCUMULATION_STEPS = 1\n",
    "# Tuning in https://mccormickml.com/2019/07/22/BERT-fine-tuning/#41-bertforsequenceclassification\n",
    "#NUM_TRAIN_EPOCHS = 20\n",
    "NUM_TRAIN_EPOCHS = 8\n",
    "#LEARNING_RATE = 5e-5\n",
    "LEARNING_RATE = 1e-5\n",
    "WARMUP_PROPORTION = 0.1\n",
    "MAX_GRAD_NORM = 5\n",
    "\n",
    "num_train_steps = int(len(f_train_dataloader.dataset) / BATCH_SIZE / GRADIENT_ACCUMULATION_STEPS * NUM_TRAIN_EPOCHS)\n",
    "num_warmup_steps = 600 #int(WARMUP_PROPORTION * num_train_steps)\n",
    "\n",
    "param_optimizer = list(f_model.named_parameters())\n",
    "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
    "optimizer_grouped_parameters = [\n",
    "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
    "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
    "    ]\n",
    "\n",
    "optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE, correct_bias=False)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps,num_training_steps=num_train_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba77d76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3849a1fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm import trange\n",
    "#from tqdm import tqdm_notebook as tqdm\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import classification_report, precision_recall_fscore_support\n",
    "\n",
    " # tuning guide:https://pytorch.org/tutorials/recipes/recipes/tuning_guide.html\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "loss_history = []\n",
    "no_improvement = 0\n",
    "NUM_TRAIN_EPOCHS=8\n",
    "for _ in trange(int(NUM_TRAIN_EPOCHS), desc=\"Epoch\"):\n",
    "    f_model.train()\n",
    "    tr_loss = 0\n",
    "    nb_tr_examples, nb_tr_steps = 0, 0\n",
    "    \n",
    "    for step, batch in enumerate(tqdm(f_train_dataloader, desc=\"Training iteration\")):\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        input_ids, input_mask, segment_ids, label_ids = batch\n",
    "        #outputs = model(input_ids, attention_mask=input_mask, token_type_ids=segment_ids, labels=label_ids)\n",
    "        outputs = f_model(input_ids, attention_mask=input_mask,labels=label_ids)\n",
    "        loss = outputs[0]\n",
    "\n",
    "        if GRADIENT_ACCUMULATION_STEPS > 1:\n",
    "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
    "\n",
    "        loss.backward()\n",
    "        tr_loss += loss.item()\n",
    "\n",
    "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
    "            torch.nn.utils.clip_grad_norm_(f_model.parameters(), MAX_GRAD_NORM)  \n",
    "            \n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad(set_to_none=True)\n",
    "            scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585a8bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm the error data should not be predicted correctly.\n",
    "texts=[str_to_predict]\n",
    "labels=[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda16ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    # Enable GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    f_model.to(device)\n",
    "    \n",
    "    # Convert text and labels to embeddings \n",
    "    features = convert_examples_to_inputs(texts, labels, label2idx, MAX_SEQ_LENGTH, tokenizer)\n",
    "    dataloader = get_data_loader(features, MAX_SEQ_LENGTH, BATCH_SIZE, shuffle=False)\n",
    "    \n",
    "    # Predict the result, and discard the evaluatoin result, only take the prediction result.\n",
    "    _, correct, predicted = evaluate(f_model, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008c1725",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(correct,predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3bc2f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a758a7fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "f_inputs = f_tokenizer(str_to_predict, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    f_logits = f_model(**f_inputs.to(device)).logits\n",
    "\n",
    "predicted_class_id = f_logits.argmax().item()\n",
    "f_model.config.id2label[predicted_class_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e9d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Plot histogram with the length. Truncate max length to 5000 tokens.\n",
    "plt.style.use(\"ggplot\")\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "train_data['length'] = train_data['original_text'].apply(lambda x: len(x.split()))\n",
    "sns.distplot(train_data[train_data['length'] < 5000]['length'])\n",
    "plt.title('Frequence of documents of a given length', fontsize=14)\n",
    "plt.xlabel('length', fontsize=14)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a42eb843",
   "metadata": {},
   "source": [
    "##### BERT-topic model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92ab77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bertopic import BERTopic\n",
    "\n",
    "from transformers.pipelines import pipeline\n",
    "\n",
    "#sentence_model = SentenceTransformer(\"xlm-r-bert-base-nli-stsb-mean-tokens\", device=\"cuda\")\n",
    "topic_model = BERTopic(language=\"english\", calculate_probabilities=True, verbose=True)\n",
    "#topics, probs = topic_model.fit_transform(train_data['original_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbd5fcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# topics for error data\n",
    "err_topics, err_probs = topic_model.fit_transform(test_data['original_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f7804d",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_data[error_data['original_text']==\"olawe\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c6d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs=error_data['original_text'].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2ea042",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir(topic_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c77711a",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.get_topic_info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496d14ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_distribution(probs[200], min_probability=0.015)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62a08712",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_barchart(top_n_topics=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005e70d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_model.visualize_heatmap(n_clusters=20, width=1000, height=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa530fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for sentences with similiar words count\n",
    "width=0\n",
    "df_range=train_data[train_data['length']<=train_data.iloc[j]['length']+width].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ae62cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_range)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53992ca5",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_range=embedder.encode(df_range['original_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf849090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clustering algorithms\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans, MiniBatchKMeans\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Elbow criterion - Determine optimal numbers of clusters by elbow rule.\n",
    "def elbow_plot(data, maxK=15, seed_centroids=None):\n",
    "    \"\"\"\n",
    "        parameters:\n",
    "        - data: pandas DataFrame (data to be fitted)\n",
    "        - maxK (default = 10): integer (maximum number of clusters with which to run k-means)\n",
    "        - seed_centroids (default = None ): float (initial value of centroids for k-means)\n",
    "    \"\"\"\n",
    "    sse = []\n",
    "    K= range(1, maxK)\n",
    "    for k in K:\n",
    "        if seed_centroids is not None:\n",
    "            seeds = seed_centroids.head(k)\n",
    "            kmeans = KMeans(n_clusters=k, max_iter=500, n_init=100, random_state=0, init=np.reshape(seeds, (k,1))).fit(data)\n",
    "            #data[\"clusters\"] = kmeans.labels_\n",
    "        else:\n",
    "            kmeans = KMeans(n_clusters=k, max_iter=300, n_init=100, random_state=0).fit(data)\n",
    "            #data[\"clusters\"] = kmeans.labels_\n",
    "        print(\"k: \", k,\"sse: \",kmeans.inertia_)\n",
    "        # Inertia: Sum of distances of samples to their closest cluster center\n",
    "        sse.append(kmeans.inertia_)\n",
    "    plt.figure()\n",
    "    plt.plot(K,sse,'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Sum_of_squared_distances')\n",
    "    plt.title('Elbow Method For Optimal k')\n",
    "    plt.show()\n",
    "    return kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d569936",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Elbow for full training data\n",
    "elbow_plot(embedding_range,maxK=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ff2d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 2\n",
    "clf = KMeans(n_clusters=num_clusters, \n",
    "            max_iter=100, \n",
    "            init='k-means++', \n",
    "            n_init=1)\n",
    "clf.fit_predict(embedding_range)\n",
    "cluster_assignment = clf.labels_\n",
    "\n",
    "cdf=pd.DataFrame(columns=[\"cluster_id\",\"sentence_id\",\"sentence\"])\n",
    "\n",
    "for i in range(len(cluster_assignment)):\n",
    "    new_row=pd.Series(data={\"cluster_id\":cluster_assignment[i],\n",
    "                                \"sentence_id\":df_range.iloc[i]['index'],\n",
    "                                \"sentence\":df_range.iloc[i]['original_text']\n",
    "                           }\n",
    "                            )\n",
    "    cdf=cdf.append(new_row,ignore_index=True)\n",
    "\n",
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad04f090",
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b35aea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PCA to reduce the dimension to project the result to 2-d scatter plot\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(embedding_range)\n",
    "\n",
    "df_pca = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "df_pca['sentence_id']=df_range['index']\n",
    "# Combine PCA results with K-means results to see clustering\n",
    "df_k=df_pca.merge(cdf,right_on=['sentence_id'],left_on=['sentence_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb6238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0845a09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ls_clusters=pd.unique(df_k[\"cluster_id\"])\n",
    "#ls_colors=df_k[\"cluster_id\"].astype('category').cat.codes\n",
    "for id in range(len(ls_clusters)):\n",
    "    ax.scatter(df_k[df_k['cluster_id']==ls_clusters[id]]['principal component 1'],\n",
    "               df_k[df_k['cluster_id']==ls_clusters[id]]['principal component 2'],label=ls_clusters[id],\n",
    "               alpha=0.3, edgecolors='none')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef726fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df_k[df_k['cluster_id']==0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb35efd3",
   "metadata": {},
   "source": [
    "#### Spelling error correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a15ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# correct spelling error to check whether accuracy could be improved.\n",
    "#from textblob import TextBlob\n",
    "#error_data['correct_text_0'] = error_data['original_text'].apply(lambda x :TextBlob(x).correct())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e160051",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autocorrect import Speller\n",
    "import re\n",
    "\n",
    "spell=Speller(lang=\"en\")\n",
    "WORD = re.compile(r'\\w+')\n",
    "def reTokenize(doc):\n",
    "    tokens = WORD.findall(doc)\n",
    "    return tokens\n",
    "\n",
    "text = [\"Hi, welcmoe to speling.\",\"This is jsut an exapmle, but cosnider a veri big coprus.\"]\n",
    "def spell_correct(text):\n",
    "    sptext = []\n",
    "    for doc in text:\n",
    "        sptext.append(' '.join([spell(w).lower() for w in reTokenize(doc)]))      \n",
    "    return sptext    \n",
    "\n",
    "print(spell_correct(text)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b79b8b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "correct_text=[]\n",
    "for i in trange(len(error_data)):\n",
    "    correct_text.append(TextBlob(error_data['original_text'].iloc[i]).correct())\n",
    "error_data['correct_text_0'] = correct_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32f17be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import trange\n",
    "correct_text=[]\n",
    "for i in trange(len(error_data)):\n",
    "    correct_text.append(' '.join([spell(w).lower() for w in reTokenize(error_data['original_text'].iloc[i])]))\n",
    "error_data['correct_text_1'] = correct_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0819fc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=list(error_data[\"correct_text_0\"])\n",
    "labels=list(error_data[\"label\"])\n",
    "data_evaluation(texts,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead2051",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b64ba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=list(error_data[\"correct_text_1\"])\n",
    "labels=list(error_data[\"label\"])\n",
    "data_evaluation(texts,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6943046d",
   "metadata": {},
   "source": [
    "##### The above result suggests spelling check could improve 13% accuracy, however, the performance of spelling check is not encouraging."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def19571",
   "metadata": {},
   "outputs": [],
   "source": [
    "#error_data.to_csv(\"./tmp/error_data_20221006.csv\",index=False) # export error data to csv for manual check"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e097188d",
   "metadata": {},
   "source": [
    "#### Clean text to see whether that would improve accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f8dd67",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=list(error_data[\"clean_text\"])\n",
    "labels=list(error_data[\"label\"])\n",
    "data_evaluation(texts,labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "345b5fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from text_preprocessing import preprocess_text\n",
    "from text_preprocessing import to_lower, remove_punctuation,remove_special_character,normalize_unicode,check_spelling,remove_stopword,lemmatize_word\n",
    "# Preprocess text using custom preprocess functions in the pipeline \n",
    "STOPWORDS=['-RRB-','-LRB-'] # remove customized stopwords\n",
    "preprocess_functions = [to_lower, remove_punctuation,remove_special_character,normalize_unicode,remove_stopword,lemmatize_word]\n",
    "error_data['preprocess_text'] = error_data['correct_text_1'].apply(lambda x:' '.join(remove_stopword(preprocess_text(x,preprocess_functions),\n",
    "                                                                                          stop_words=STOPWORDS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2502970",
   "metadata": {},
   "outputs": [],
   "source": [
    "error_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5add739",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts=list(error_data[\"preprocess_text\"])\n",
    "labels=list(error_data[\"label\"])\n",
    "data_evaluation(texts,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b243c6f",
   "metadata": {},
   "source": [
    "#### The accuracy of error list was improved to 34%, and it looks like the preprocessing text do help to improve accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cbfd0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_path=\"./01_data/WikiLarge_Train.csv\"\n",
    "train_data=pd.read_csv(train_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8048d3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_text=[]\n",
    "for i in trange(len(train_data)):\n",
    "    correct_text.append(' '.join([spell(w).lower() for w in reTokenize(train_data['original_text'].iloc[i])]))\n",
    "train_data['correct_text_1'] = correct_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08884ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"./tmp/train_data_correction.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7692f39f",
   "metadata": {},
   "source": [
    "##### Given the above improvement, and try to apply this to test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8325e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the test data for submission\n",
    "sub_data_path=\"./01_data/WikiLarge_Test.csv\"\n",
    "sub_data=pd.read_csv(sub_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3457cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_text=[]\n",
    "for i in trange(len(sub_data)):\n",
    "    correct_text.append(' '.join([spell(w).lower() for w in reTokenize(sub_data['original_text'].iloc[i])]))\n",
    "sub_data['correct_text_1'] = correct_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee62584",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sub_data['original_text'] = sub_data['correct_text_1'].apply(lambda x:' '.join(remove_stopword(preprocess_text(x,preprocess_functions),\n",
    "#                                                                                          stop_words=STOPWORDS)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146cb0e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_data.to_csv(\"./tmp/sub_data_correction.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17289bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_texts=list(sub_data[\"correct_text_1\"])\n",
    "sub_labels=[1 for i in range(len(sub_texts))]\n",
    "\n",
    "print(\"Submission Test size:\", len(sub_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aa4915",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, sub_predicted=data_evaluation(sub_texts,sub_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ce1271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the submission file\n",
    "df_sub=pd.DataFrame(columns=[\"id\",\"label\"])\n",
    "df_sub['label']=sub_predicted\n",
    "df_sub['id']=[i for i in range(len(sub_predicted))]\n",
    "df_sub.to_csv(\"./tmp/submission.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469e40c0",
   "metadata": {},
   "source": [
    "### Embedding-based clustering analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0b04163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Other utils\n",
    "from tqdm import tqdm  # Progress bar\n",
    "# Transformers\n",
    "from transformers import pipeline\n",
    "import ipywidgets as widgets\n",
    "from transformers import pipeline\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b6c4c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#onlinemodel='distiluse-base-multilingual-cased-v2'\n",
    "onlinemodel=\"all-mpnet-base-v2\"\n",
    "embedder = SentenceTransformer(onlinemodel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359c7193",
   "metadata": {},
   "outputs": [],
   "source": [
    "queries= list(error_data['original_text'])\n",
    "query_embeddings=embedder.encode(queries)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b48efb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Elbow criterion - Determine optimal numbers of clusters by elbow rule.\n",
    "def elbow_plot(data, maxK=15, seed_centroids=None):\n",
    "    \"\"\"\n",
    "        parameters:\n",
    "        - data: pandas DataFrame (data to be fitted)\n",
    "        - maxK (default = 10): integer (maximum number of clusters with which to run k-means)\n",
    "        - seed_centroids (default = None ): float (initial value of centroids for k-means)\n",
    "    \"\"\"\n",
    "    sse = []\n",
    "    K= range(1, maxK)\n",
    "    for k in K:\n",
    "        if seed_centroids is not None:\n",
    "            seeds = seed_centroids.head(k)\n",
    "            kmeans = KMeans(n_clusters=k, max_iter=500, n_init=100, random_state=0, init=np.reshape(seeds, (k,1))).fit(data)\n",
    "            #data[\"clusters\"] = kmeans.labels_\n",
    "        else:\n",
    "            kmeans = KMeans(n_clusters=k, max_iter=300, n_init=100, random_state=0).fit(data)\n",
    "            #data[\"clusters\"] = kmeans.labels_\n",
    "        print(\"k: \", k,\"sse: \",kmeans.inertia_)\n",
    "        # Inertia: Sum of distances of samples to their closest cluster center\n",
    "        sse.append(kmeans.inertia_)\n",
    "    plt.figure()\n",
    "    plt.plot(K,sse,'bx-')\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('Sum_of_squared_distances')\n",
    "    plt.title('Elbow Method For Optimal k')\n",
    "    plt.show()\n",
    "    return kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3515b699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run Elbow for full training data\n",
    "elbow_plot(query_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd266e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create clustering dataframe \n",
    "def df_clustering(queries, embeddings, labels=None, clusters=2):\n",
    "    \"\"\"\n",
    "        parameters:\n",
    "        - queries: list of queries\n",
    "        - embeddings: list of embeddings corresponding to queries\n",
    "        - clusters: no. of clusters for kmeans\n",
    "    \"\"\"\n",
    "    num_clusters = clusters\n",
    "    clf = KMeans(n_clusters=num_clusters, \n",
    "                max_iter=100, \n",
    "                init='k-means++', \n",
    "                n_init=1)\n",
    "    clf.fit_predict(embeddings)\n",
    "    cluster_assignment = clf.labels_\n",
    "\n",
    "    cdf=pd.DataFrame(columns=[\"cluster_id\",\"sentence_id\",\"sentence\",'label'])\n",
    "\n",
    "    cdf['cluster_id']=clf.labels_\n",
    "    cdf['sentence_id']=[i for i in range(len(clf.labels_))]\n",
    "    cdf['sentence']=queries\n",
    "    cdf['label']=labels\n",
    "                                            \n",
    "    return cdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9775bc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_clusters = 4\n",
    "clf = KMeans(n_clusters=num_clusters, \n",
    "            max_iter=100, \n",
    "            init='k-means++', \n",
    "            n_init=1)\n",
    "clf.fit_predict(query_embeddings)\n",
    "cluster_assignment = clf.labels_\n",
    "\n",
    "cdf=pd.DataFrame(columns=[\"cluster_id\",\"sentence_id\",\"sentence\"])\n",
    "\n",
    "for i in range(len(cluster_assignment)):\n",
    "    new_row=pd.DataFrame({\"cluster_id\":[cluster_assignment[i]],\n",
    "                                \"sentence_id\":[i],\n",
    "                                \"sentence\":[queries[i]]\n",
    "                           })\n",
    "    cdf=pd.concat([cdf,new_row],axis=0,ignore_index=True)\n",
    "\n",
    "cdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254067b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using PCA to reduce the dimension to project the result to 2-d scatter plot\n",
    "pca = PCA(n_components=2)\n",
    "principalComponents = pca.fit_transform(query_embeddings)\n",
    "\n",
    "df_pca = pd.DataFrame(data = principalComponents\n",
    "             , columns = ['principal component 1', 'principal component 2'])\n",
    "\n",
    "df_pca['sentence']=queries\n",
    "# Combine PCA results with K-means results to see clustering\n",
    "df_k=df_pca.merge(cdf,right_on=['sentence'],left_on=['sentence'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b94adcc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ls_clusters=pd.unique(df_k[\"cluster_id\"])\n",
    "ls_colors=['tab:blue', 'tab:orange', 'tab:green','tab:purple']\n",
    "#ls_colors=df_k[\"cluster_id\"].astype('category').cat.codes\n",
    "for id in range(len(ls_clusters)):\n",
    "    ax.scatter(df_k[df_k['cluster_id']==ls_clusters[id]]['principal component 1'],\n",
    "               df_k[df_k['cluster_id']==ls_clusters[id]]['principal component 2'], c=ls_colors[id], label=ls_clusters[id],\n",
    "               alpha=0.9, edgecolors='none')\n",
    "\n",
    "ax.legend()\n",
    "ax.grid(True)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d6b29b8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
